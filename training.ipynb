{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 18:34:33.071452: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-30 18:34:33.769442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "from rlpyt.samplers.collections import TrajInfo\n",
    "from rlpyt.runners.minibatch_rl import MinibatchRlEval, MinibatchRl\n",
    "from rlpyt.samplers.serial.sampler import SerialSampler\n",
    "from rlpyt.utils.logging.context import logger_context\n",
    "\n",
    "from dreamer_agent import DMCDreamerAgent\n",
    "from algorithm import Dreamer\n",
    "from envs.dmc import DeepMindControl\n",
    "from envs.time_limit import TimeLimit\n",
    "from envs.action_repeat import ActionRepeat\n",
    "from envs.normalize_actions import NormalizeActions\n",
    "from envs.wrapper import make_wapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_train(\n",
    "    log_dir,\n",
    "    game=\"cartpole_balance\",\n",
    "    run_ID=0,\n",
    "    cuda_idx=None,\n",
    "    eval=False,\n",
    "    save_model=\"last\",\n",
    "    load_model_path=None,\n",
    "):\n",
    "    params = torch.load(load_model_path) if load_model_path else {}\n",
    "    agent_state_dict = params.get(\"agent_state_dict\")\n",
    "    optimizer_state_dict = params.get(\"optimizer_state_dict\")\n",
    "    action_repeat = 2\n",
    "    factory_method = make_wapper(\n",
    "        DeepMindControl,\n",
    "        [ActionRepeat, NormalizeActions, TimeLimit],\n",
    "        [dict(amount=action_repeat), dict(), dict(duration=1000 / action_repeat)],\n",
    "    )\n",
    "    sampler = SerialSampler(\n",
    "        EnvCls=factory_method,\n",
    "        TrajInfoCls=TrajInfo,\n",
    "        env_kwargs=dict(name=game),\n",
    "        eval_env_kwargs=dict(name=game),\n",
    "        batch_T=1,\n",
    "        batch_B=1,\n",
    "        max_decorrelation_steps=0,\n",
    "        eval_n_envs=10,\n",
    "        eval_max_steps=int(10e3),\n",
    "        eval_max_trajectories=5,\n",
    "    )\n",
    "    algo = Dreamer(initial_optim_state_dict=optimizer_state_dict)  # Run with defaults.\n",
    "    agent = DMCDreamerAgent(\n",
    "        train_noise=0.3,\n",
    "        eval_noise=0,\n",
    "        expl_type=\"additive_gaussian\",\n",
    "        expl_min=None,\n",
    "        expl_decay=None,\n",
    "        initial_model_state_dict=agent_state_dict,\n",
    "    )\n",
    "    runner_cls = MinibatchRlEval if eval else MinibatchRl\n",
    "    runner = runner_cls(\n",
    "        algo=algo,\n",
    "        agent=agent,\n",
    "        sampler=sampler,\n",
    "        n_steps=5000,\n",
    "        log_interval_steps=1e3,\n",
    "        affinity=dict(cuda_idx=cuda_idx),\n",
    "    )\n",
    "    config = dict(game=game)\n",
    "    name = \"dreamer_\" + game\n",
    "    with logger_context(\n",
    "        log_dir,\n",
    "        run_ID,\n",
    "        name,\n",
    "        config,\n",
    "        snapshot_mode=save_model,\n",
    "        override_prefix=True,\n",
    "        use_summary_writer=True,\n",
    "    ):\n",
    "        runner.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-30 18:34:34.640625  | dreamer_humanoid_stand_0 Runner  master CPU affinity: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11].\n",
      "2023-12-30 18:34:34.641046  | dreamer_humanoid_stand_0 Runner  master Torch threads: 6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32musing seed 1564\u001b[0m\n",
      "2023-12-30 18:34:36.069779  | dreamer_humanoid_stand_0 Sampler decorrelating envs, max steps: 0\n",
      "2023-12-30 18:34:36.070504  | dreamer_humanoid_stand_0 Serial Sampler initialized.\n",
      "2023-12-30 18:34:36.070996  | dreamer_humanoid_stand_0 Running 50000 iterations of minibatch RL.\n",
      "2023-12-30 18:34:36.848658  | dreamer_humanoid_stand_0 Initialized agent model on device: cuda:0.\n",
      "DAI CHE SIAMO VICINIIIIIIII\n",
      "size passato a SequenceNStepReturnBuffer = 50000\n",
      "2023-12-30 18:34:36.868767  | dreamer_humanoid_stand_0 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eddy/.local/lib/python3.10/site-packages/torch/optim/adam.py:33: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super().__init__(params, defaults)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-30 18:34:45.506017  | dreamer_humanoid_stand_0 itr #999 saving snapshot...\n",
      "2023-12-30 18:34:45.553742  | dreamer_humanoid_stand_0 itr #999 saved\n",
      "2023-12-30 18:34:45.559984  | -----------------------------  ----------\n",
      "2023-12-30 18:34:45.560600  | Diagnostics/NewCompletedTrajs     2\n",
      "2023-12-30 18:34:45.561090  | Diagnostics/StepsInTrajWindow  1000\n",
      "2023-12-30 18:34:45.561706  | Diagnostics/Iteration           999\n",
      "2023-12-30 18:34:45.562314  | Diagnostics/CumTime (s)           8.68515\n",
      "2023-12-30 18:34:45.562752  | Diagnostics/CumSteps           1000\n",
      "2023-12-30 18:34:45.563172  | Diagnostics/CumCompletedTrajs     2\n",
      "2023-12-30 18:34:45.563788  | Diagnostics/CumUpdates            0\n",
      "2023-12-30 18:34:45.564300  | Diagnostics/StepsPerSecond      115.139\n",
      "2023-12-30 18:34:45.564665  | Diagnostics/UpdatesPerSecond      0\n",
      "2023-12-30 18:34:45.565152  | Diagnostics/ReplayRatio           0\n",
      "2023-12-30 18:34:45.565600  | Diagnostics/CumReplayRatio        0\n",
      "2023-12-30 18:34:45.565911  | Length/Average                  500\n",
      "2023-12-30 18:34:45.566412  | Length/Std                        0\n",
      "2023-12-30 18:34:45.567098  | Length/Median                   500\n",
      "2023-12-30 18:34:45.567567  | Length/Min                      500\n",
      "2023-12-30 18:34:45.568180  | Length/Max                      500\n",
      "2023-12-30 18:34:45.568642  | Return/Average                    5.85442\n",
      "2023-12-30 18:34:45.569095  | Return/Std                        4.15138\n",
      "2023-12-30 18:34:45.569527  | Return/Median                     5.85442\n",
      "2023-12-30 18:34:45.569916  | Return/Min                        1.70304\n",
      "2023-12-30 18:34:45.570451  | Return/Max                       10.0058\n",
      "2023-12-30 18:34:45.570916  | NonzeroRewards/Average          500\n",
      "2023-12-30 18:34:45.571241  | NonzeroRewards/Std                0\n",
      "2023-12-30 18:34:45.571555  | NonzeroRewards/Median           500\n",
      "2023-12-30 18:34:45.571862  | NonzeroRewards/Min              500\n",
      "2023-12-30 18:34:45.572224  | NonzeroRewards/Max              500\n",
      "2023-12-30 18:34:45.573018  | DiscountedReturn/Average          5.7128\n",
      "2023-12-30 18:34:45.573444  | DiscountedReturn/Std              4.03328\n",
      "2023-12-30 18:34:45.574296  | DiscountedReturn/Median           5.7128\n",
      "2023-12-30 18:34:45.574944  | DiscountedReturn/Min              1.67952\n",
      "2023-12-30 18:34:45.575448  | DiscountedReturn/Max              9.74608\n",
      "2023-12-30 18:34:45.575825  | loss/Average                    nan\n",
      "2023-12-30 18:34:45.576284  | loss/Std                        nan\n",
      "2023-12-30 18:34:45.576646  | loss/Median                     nan\n",
      "2023-12-30 18:34:45.577059  | loss/Min                        nan\n",
      "2023-12-30 18:34:45.577481  | loss/Max                        nan\n",
      "2023-12-30 18:34:45.577887  | grad_norm_model/Average         nan\n",
      "2023-12-30 18:34:45.578296  | grad_norm_model/Std             nan\n",
      "2023-12-30 18:34:45.578746  | grad_norm_model/Median          nan\n",
      "2023-12-30 18:34:45.579183  | grad_norm_model/Min             nan\n",
      "2023-12-30 18:34:45.579629  | grad_norm_model/Max             nan\n",
      "2023-12-30 18:34:45.581349  | grad_norm_actor/Average         nan\n",
      "2023-12-30 18:34:45.581829  | grad_norm_actor/Std             nan\n",
      "2023-12-30 18:34:45.582277  | grad_norm_actor/Median          nan\n",
      "2023-12-30 18:34:45.582724  | grad_norm_actor/Min             nan\n",
      "2023-12-30 18:34:45.583131  | grad_norm_actor/Max             nan\n",
      "2023-12-30 18:34:45.583551  | grad_norm_value/Average         nan\n",
      "2023-12-30 18:34:45.583960  | grad_norm_value/Std             nan\n",
      "2023-12-30 18:34:45.585475  | grad_norm_value/Median          nan\n",
      "2023-12-30 18:34:45.586241  | grad_norm_value/Min             nan\n",
      "2023-12-30 18:34:45.586680  | grad_norm_value/Max             nan\n",
      "2023-12-30 18:34:45.587198  | model_loss/Average              nan\n",
      "2023-12-30 18:34:45.587708  | model_loss/Std                  nan\n",
      "2023-12-30 18:34:45.588313  | model_loss/Median               nan\n",
      "2023-12-30 18:34:45.588838  | model_loss/Min                  nan\n",
      "2023-12-30 18:34:45.589381  | model_loss/Max                  nan\n",
      "2023-12-30 18:34:45.590048  | actor_loss/Average              nan\n",
      "2023-12-30 18:34:45.590450  | actor_loss/Std                  nan\n",
      "2023-12-30 18:34:45.591116  | actor_loss/Median               nan\n",
      "2023-12-30 18:34:45.591620  | actor_loss/Min                  nan\n",
      "2023-12-30 18:34:45.592081  | actor_loss/Max                  nan\n",
      "2023-12-30 18:34:45.592580  | value_loss/Average              nan\n",
      "2023-12-30 18:34:45.592908  | value_loss/Std                  nan\n",
      "2023-12-30 18:34:45.593222  | value_loss/Median               nan\n",
      "2023-12-30 18:34:45.593748  | value_loss/Min                  nan\n",
      "2023-12-30 18:34:45.594277  | value_loss/Max                  nan\n",
      "2023-12-30 18:34:45.594608  | prior_entropy/Average           nan\n",
      "2023-12-30 18:34:45.594996  | prior_entropy/Std               nan\n",
      "2023-12-30 18:34:45.595424  | prior_entropy/Median            nan\n",
      "2023-12-30 18:34:45.595758  | prior_entropy/Min               nan\n",
      "2023-12-30 18:34:45.596406  | prior_entropy/Max               nan\n",
      "2023-12-30 18:34:45.596941  | post_entropy/Average            nan\n",
      "2023-12-30 18:34:45.597419  | post_entropy/Std                nan\n",
      "2023-12-30 18:34:45.597888  | post_entropy/Median             nan\n",
      "2023-12-30 18:34:45.598381  | post_entropy/Min                nan\n",
      "2023-12-30 18:34:45.599366  | post_entropy/Max                nan\n",
      "2023-12-30 18:34:45.599830  | divergence/Average              nan\n",
      "2023-12-30 18:34:45.600288  | divergence/Std                  nan\n",
      "2023-12-30 18:34:45.601105  | divergence/Median               nan\n",
      "2023-12-30 18:34:45.601835  | divergence/Min                  nan\n",
      "2023-12-30 18:34:45.602348  | divergence/Max                  nan\n",
      "2023-12-30 18:34:45.602788  | reward_loss/Average             nan\n",
      "2023-12-30 18:34:45.603220  | reward_loss/Std                 nan\n",
      "2023-12-30 18:34:45.603642  | reward_loss/Median              nan\n",
      "2023-12-30 18:34:45.604098  | reward_loss/Min                 nan\n",
      "2023-12-30 18:34:45.605092  | reward_loss/Max                 nan\n",
      "2023-12-30 18:34:45.605531  | image_loss/Average              nan\n",
      "2023-12-30 18:34:45.605981  | image_loss/Std                  nan\n",
      "2023-12-30 18:34:45.606724  | image_loss/Median               nan\n",
      "2023-12-30 18:34:45.607162  | image_loss/Min                  nan\n",
      "2023-12-30 18:34:45.607861  | image_loss/Max                  nan\n",
      "2023-12-30 18:34:45.608326  | pcont_loss/Average              nan\n",
      "2023-12-30 18:34:45.608655  | pcont_loss/Std                  nan\n",
      "2023-12-30 18:34:45.609081  | pcont_loss/Median               nan\n",
      "2023-12-30 18:34:45.609435  | pcont_loss/Min                  nan\n",
      "2023-12-30 18:34:45.609765  | pcont_loss/Max                  nan\n",
      "2023-12-30 18:34:45.610086  | -----------------------------  ----------\n",
      "2023-12-30 18:34:45.610759  | dreamer_humanoid_stand_0 itr #999 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n",
      "2023-12-30 18:34:53.822391  | dreamer_humanoid_stand_0 itr #1999 saving snapshot...\n",
      "2023-12-30 18:34:53.878728  | dreamer_humanoid_stand_0 itr #1999 saved\n",
      "2023-12-30 18:34:53.895896  | -----------------------------  -----------\n",
      "2023-12-30 18:34:53.897412  | Diagnostics/NewCompletedTrajs     2\n",
      "2023-12-30 18:34:53.898228  | Diagnostics/StepsInTrajWindow  2000\n",
      "2023-12-30 18:34:53.899335  | Diagnostics/Iteration          1999\n",
      "2023-12-30 18:34:53.899920  | Diagnostics/CumTime (s)          17.0111\n",
      "2023-12-30 18:34:53.900331  | Diagnostics/CumSteps           2000\n",
      "2023-12-30 18:34:53.900669  | Diagnostics/CumCompletedTrajs     4\n",
      "2023-12-30 18:34:53.900992  | Diagnostics/CumUpdates            0\n",
      "2023-12-30 18:34:53.901382  | Diagnostics/StepsPerSecond      120.106\n",
      "2023-12-30 18:34:53.902056  | Diagnostics/UpdatesPerSecond      0\n",
      "2023-12-30 18:34:53.902618  | Diagnostics/ReplayRatio           0\n",
      "2023-12-30 18:34:53.903117  | Diagnostics/CumReplayRatio        0\n",
      "2023-12-30 18:34:53.903479  | Length/Average                  500\n",
      "2023-12-30 18:34:53.903800  | Length/Std                        0\n",
      "2023-12-30 18:34:53.904519  | Length/Median                   500\n",
      "2023-12-30 18:34:53.904972  | Length/Min                      500\n",
      "2023-12-30 18:34:53.905318  | Length/Max                      500\n",
      "2023-12-30 18:34:53.905675  | Return/Average                    3.99088\n",
      "2023-12-30 18:34:53.906320  | Return/Std                        3.71387\n",
      "2023-12-30 18:34:53.906673  | Return/Median                     2.83798\n",
      "2023-12-30 18:34:53.906989  | Return/Min                        0.281761\n",
      "2023-12-30 18:34:53.907348  | Return/Max                       10.0058\n",
      "2023-12-30 18:34:53.908048  | NonzeroRewards/Average          500\n",
      "2023-12-30 18:34:53.908364  | NonzeroRewards/Std                0\n",
      "2023-12-30 18:34:53.908851  | NonzeroRewards/Median           500\n",
      "2023-12-30 18:34:53.909141  | NonzeroRewards/Min              500\n",
      "2023-12-30 18:34:53.909402  | NonzeroRewards/Max              500\n",
      "2023-12-30 18:34:53.909717  | DiscountedReturn/Average          3.90039\n",
      "2023-12-30 18:34:53.910024  | DiscountedReturn/Std              3.61346\n",
      "2023-12-30 18:34:53.910631  | DiscountedReturn/Median           2.78889\n",
      "2023-12-30 18:34:53.910917  | DiscountedReturn/Min              0.277694\n",
      "2023-12-30 18:34:53.911245  | DiscountedReturn/Max              9.74608\n",
      "2023-12-30 18:34:53.911823  | loss/Average                    nan\n",
      "2023-12-30 18:34:53.912243  | loss/Std                        nan\n",
      "2023-12-30 18:34:53.912714  | loss/Median                     nan\n",
      "2023-12-30 18:34:53.913011  | loss/Min                        nan\n",
      "2023-12-30 18:34:53.913341  | loss/Max                        nan\n",
      "2023-12-30 18:34:53.914226  | grad_norm_model/Average         nan\n",
      "2023-12-30 18:34:53.914890  | grad_norm_model/Std             nan\n",
      "2023-12-30 18:34:53.915425  | grad_norm_model/Median          nan\n",
      "2023-12-30 18:34:53.915762  | grad_norm_model/Min             nan\n",
      "2023-12-30 18:34:53.916088  | grad_norm_model/Max             nan\n",
      "2023-12-30 18:34:53.916455  | grad_norm_actor/Average         nan\n",
      "2023-12-30 18:34:53.916794  | grad_norm_actor/Std             nan\n",
      "2023-12-30 18:34:53.917474  | grad_norm_actor/Median          nan\n",
      "2023-12-30 18:34:53.917928  | grad_norm_actor/Min             nan\n",
      "2023-12-30 18:34:53.918296  | grad_norm_actor/Max             nan\n",
      "2023-12-30 18:34:53.918992  | grad_norm_value/Average         nan\n",
      "2023-12-30 18:34:53.919428  | grad_norm_value/Std             nan\n",
      "2023-12-30 18:34:53.919812  | grad_norm_value/Median          nan\n",
      "2023-12-30 18:34:53.920163  | grad_norm_value/Min             nan\n",
      "2023-12-30 18:34:53.920731  | grad_norm_value/Max             nan\n",
      "2023-12-30 18:34:53.921040  | model_loss/Average              nan\n",
      "2023-12-30 18:34:53.921487  | model_loss/Std                  nan\n",
      "2023-12-30 18:34:53.922010  | model_loss/Median               nan\n",
      "2023-12-30 18:34:53.922395  | model_loss/Min                  nan\n",
      "2023-12-30 18:34:53.922774  | model_loss/Max                  nan\n",
      "2023-12-30 18:34:53.923136  | actor_loss/Average              nan\n",
      "2023-12-30 18:34:53.923486  | actor_loss/Std                  nan\n",
      "2023-12-30 18:34:53.923949  | actor_loss/Median               nan\n",
      "2023-12-30 18:34:53.924302  | actor_loss/Min                  nan\n",
      "2023-12-30 18:34:53.924642  | actor_loss/Max                  nan\n",
      "2023-12-30 18:34:53.925222  | value_loss/Average              nan\n",
      "2023-12-30 18:34:53.925696  | value_loss/Std                  nan\n",
      "2023-12-30 18:34:53.926270  | value_loss/Median               nan\n",
      "2023-12-30 18:34:53.926980  | value_loss/Min                  nan\n",
      "2023-12-30 18:34:53.927365  | value_loss/Max                  nan\n",
      "2023-12-30 18:34:53.927802  | prior_entropy/Average           nan\n",
      "2023-12-30 18:34:53.928792  | prior_entropy/Std               nan\n",
      "2023-12-30 18:34:53.929466  | prior_entropy/Median            nan\n",
      "2023-12-30 18:34:53.929828  | prior_entropy/Min               nan\n",
      "2023-12-30 18:34:53.930401  | prior_entropy/Max               nan\n",
      "2023-12-30 18:34:53.930765  | post_entropy/Average            nan\n",
      "2023-12-30 18:34:53.931117  | post_entropy/Std                nan\n",
      "2023-12-30 18:34:53.931703  | post_entropy/Median             nan\n",
      "2023-12-30 18:34:53.932145  | post_entropy/Min                nan\n",
      "2023-12-30 18:34:53.932586  | post_entropy/Max                nan\n",
      "2023-12-30 18:34:53.932918  | divergence/Average              nan\n",
      "2023-12-30 18:34:53.933239  | divergence/Std                  nan\n",
      "2023-12-30 18:34:53.933540  | divergence/Median               nan\n",
      "2023-12-30 18:34:53.933850  | divergence/Min                  nan\n",
      "2023-12-30 18:34:53.934225  | divergence/Max                  nan\n",
      "2023-12-30 18:34:53.935109  | reward_loss/Average             nan\n",
      "2023-12-30 18:34:53.935509  | reward_loss/Std                 nan\n",
      "2023-12-30 18:34:53.936053  | reward_loss/Median              nan\n",
      "2023-12-30 18:34:53.936491  | reward_loss/Min                 nan\n",
      "2023-12-30 18:34:53.936824  | reward_loss/Max                 nan\n",
      "2023-12-30 18:34:53.937337  | image_loss/Average              nan\n",
      "2023-12-30 18:34:53.937762  | image_loss/Std                  nan\n",
      "2023-12-30 18:34:53.938185  | image_loss/Median               nan\n",
      "2023-12-30 18:34:53.938693  | image_loss/Min                  nan\n",
      "2023-12-30 18:34:53.939116  | image_loss/Max                  nan\n",
      "2023-12-30 18:34:53.939440  | pcont_loss/Average              nan\n",
      "2023-12-30 18:34:53.939786  | pcont_loss/Std                  nan\n",
      "2023-12-30 18:34:53.940180  | pcont_loss/Median               nan\n",
      "2023-12-30 18:34:53.940649  | pcont_loss/Min                  nan\n",
      "2023-12-30 18:34:53.941139  | pcont_loss/Max                  nan\n",
      "2023-12-30 18:34:53.941567  | -----------------------------  -----------\n",
      "2023-12-30 18:34:53.942226  | dreamer_humanoid_stand_0 itr #1999 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n",
      "2023-12-30 18:35:01.864221  | dreamer_humanoid_stand_0 itr #2999 saving snapshot...\n",
      "2023-12-30 18:35:01.924450  | dreamer_humanoid_stand_0 itr #2999 saved\n",
      "2023-12-30 18:35:01.930576  | -----------------------------  -----------\n",
      "2023-12-30 18:35:01.931054  | Diagnostics/NewCompletedTrajs     2\n",
      "2023-12-30 18:35:01.931484  | Diagnostics/StepsInTrajWindow  3000\n",
      "2023-12-30 18:35:01.932144  | Diagnostics/Iteration          2999\n",
      "2023-12-30 18:35:01.932604  | Diagnostics/CumTime (s)          25.0559\n",
      "2023-12-30 18:35:01.933344  | Diagnostics/CumSteps           3000\n",
      "2023-12-30 18:35:01.933944  | Diagnostics/CumCompletedTrajs     6\n",
      "2023-12-30 18:35:01.934680  | Diagnostics/CumUpdates            0\n",
      "2023-12-30 18:35:01.935118  | Diagnostics/StepsPerSecond      124.305\n",
      "2023-12-30 18:35:01.935571  | Diagnostics/UpdatesPerSecond      0\n",
      "2023-12-30 18:35:01.936540  | Diagnostics/ReplayRatio           0\n",
      "2023-12-30 18:35:01.937015  | Diagnostics/CumReplayRatio        0\n",
      "2023-12-30 18:35:01.937453  | Length/Average                  500\n",
      "2023-12-30 18:35:01.938513  | Length/Std                        0\n",
      "2023-12-30 18:35:01.939067  | Length/Median                   500\n",
      "2023-12-30 18:35:01.939652  | Length/Min                      500\n",
      "2023-12-30 18:35:01.940232  | Length/Max                      500\n",
      "2023-12-30 18:35:01.941357  | Return/Average                    3.93626\n",
      "2023-12-30 18:35:01.941979  | Return/Std                        3.18183\n",
      "2023-12-30 18:35:01.942708  | Return/Median                     3.06803\n",
      "2023-12-30 18:35:01.943542  | Return/Min                        0.281761\n",
      "2023-12-30 18:35:01.944071  | Return/Max                       10.0058\n",
      "2023-12-30 18:35:01.944749  | NonzeroRewards/Average          500\n",
      "2023-12-30 18:35:01.945347  | NonzeroRewards/Std                0\n",
      "2023-12-30 18:35:01.945910  | NonzeroRewards/Median           500\n",
      "2023-12-30 18:35:01.946315  | NonzeroRewards/Min              500\n",
      "2023-12-30 18:35:01.946728  | NonzeroRewards/Max              500\n",
      "2023-12-30 18:35:01.947161  | DiscountedReturn/Average          3.85016\n",
      "2023-12-30 18:35:01.947588  | DiscountedReturn/Std              3.09497\n",
      "2023-12-30 18:35:01.947994  | DiscountedReturn/Median           3.01663\n",
      "2023-12-30 18:35:01.948396  | DiscountedReturn/Min              0.277694\n",
      "2023-12-30 18:35:01.948811  | DiscountedReturn/Max              9.74608\n",
      "2023-12-30 18:35:01.949198  | loss/Average                    nan\n",
      "2023-12-30 18:35:01.949597  | loss/Std                        nan\n",
      "2023-12-30 18:35:01.950038  | loss/Median                     nan\n",
      "2023-12-30 18:35:01.950459  | loss/Min                        nan\n",
      "2023-12-30 18:35:01.950891  | loss/Max                        nan\n",
      "2023-12-30 18:35:01.951301  | grad_norm_model/Average         nan\n",
      "2023-12-30 18:35:01.951692  | grad_norm_model/Std             nan\n",
      "2023-12-30 18:35:01.952070  | grad_norm_model/Median          nan\n",
      "2023-12-30 18:35:01.952518  | grad_norm_model/Min             nan\n",
      "2023-12-30 18:35:01.954920  | grad_norm_model/Max             nan\n",
      "2023-12-30 18:35:01.955408  | grad_norm_actor/Average         nan\n",
      "2023-12-30 18:35:01.955874  | grad_norm_actor/Std             nan\n",
      "2023-12-30 18:35:01.956761  | grad_norm_actor/Median          nan\n",
      "2023-12-30 18:35:01.957366  | grad_norm_actor/Min             nan\n",
      "2023-12-30 18:35:01.957880  | grad_norm_actor/Max             nan\n",
      "2023-12-30 18:35:01.958217  | grad_norm_value/Average         nan\n",
      "2023-12-30 18:35:01.958632  | grad_norm_value/Std             nan\n",
      "2023-12-30 18:35:01.958991  | grad_norm_value/Median          nan\n",
      "2023-12-30 18:35:01.959301  | grad_norm_value/Min             nan\n",
      "2023-12-30 18:35:01.959701  | grad_norm_value/Max             nan\n",
      "2023-12-30 18:35:01.959985  | model_loss/Average              nan\n",
      "2023-12-30 18:35:01.960244  | model_loss/Std                  nan\n",
      "2023-12-30 18:35:01.960973  | model_loss/Median               nan\n",
      "2023-12-30 18:35:01.961712  | model_loss/Min                  nan\n",
      "2023-12-30 18:35:01.962110  | model_loss/Max                  nan\n",
      "2023-12-30 18:35:01.962507  | actor_loss/Average              nan\n",
      "2023-12-30 18:35:01.963026  | actor_loss/Std                  nan\n",
      "2023-12-30 18:35:01.963405  | actor_loss/Median               nan\n",
      "2023-12-30 18:35:01.963965  | actor_loss/Min                  nan\n",
      "2023-12-30 18:35:01.964532  | actor_loss/Max                  nan\n",
      "2023-12-30 18:35:01.964932  | value_loss/Average              nan\n",
      "2023-12-30 18:35:01.965509  | value_loss/Std                  nan\n",
      "2023-12-30 18:35:01.965996  | value_loss/Median               nan\n",
      "2023-12-30 18:35:01.966502  | value_loss/Min                  nan\n",
      "2023-12-30 18:35:01.967086  | value_loss/Max                  nan\n",
      "2023-12-30 18:35:01.967437  | prior_entropy/Average           nan\n",
      "2023-12-30 18:35:01.967891  | prior_entropy/Std               nan\n",
      "2023-12-30 18:35:01.968346  | prior_entropy/Median            nan\n",
      "2023-12-30 18:35:01.968749  | prior_entropy/Min               nan\n",
      "2023-12-30 18:35:01.969052  | prior_entropy/Max               nan\n",
      "2023-12-30 18:35:01.969502  | post_entropy/Average            nan\n",
      "2023-12-30 18:35:01.969937  | post_entropy/Std                nan\n",
      "2023-12-30 18:35:01.970498  | post_entropy/Median             nan\n",
      "2023-12-30 18:35:01.970868  | post_entropy/Min                nan\n",
      "2023-12-30 18:35:01.971296  | post_entropy/Max                nan\n",
      "2023-12-30 18:35:01.971663  | divergence/Average              nan\n",
      "2023-12-30 18:35:01.972008  | divergence/Std                  nan\n",
      "2023-12-30 18:35:01.972351  | divergence/Median               nan\n",
      "2023-12-30 18:35:01.972652  | divergence/Min                  nan\n",
      "2023-12-30 18:35:01.973106  | divergence/Max                  nan\n",
      "2023-12-30 18:35:01.973386  | reward_loss/Average             nan\n",
      "2023-12-30 18:35:01.973792  | reward_loss/Std                 nan\n",
      "2023-12-30 18:35:01.974199  | reward_loss/Median              nan\n",
      "2023-12-30 18:35:01.974807  | reward_loss/Min                 nan\n",
      "2023-12-30 18:35:01.975151  | reward_loss/Max                 nan\n",
      "2023-12-30 18:35:01.975489  | image_loss/Average              nan\n",
      "2023-12-30 18:35:01.976075  | image_loss/Std                  nan\n",
      "2023-12-30 18:35:01.976404  | image_loss/Median               nan\n",
      "2023-12-30 18:35:01.976751  | image_loss/Min                  nan\n",
      "2023-12-30 18:35:01.977321  | image_loss/Max                  nan\n",
      "2023-12-30 18:35:01.977620  | pcont_loss/Average              nan\n",
      "2023-12-30 18:35:01.978085  | pcont_loss/Std                  nan\n",
      "2023-12-30 18:35:01.978487  | pcont_loss/Median               nan\n",
      "2023-12-30 18:35:01.978892  | pcont_loss/Min                  nan\n",
      "2023-12-30 18:35:01.979223  | pcont_loss/Max                  nan\n",
      "2023-12-30 18:35:01.979731  | -----------------------------  -----------\n",
      "2023-12-30 18:35:01.980311  | dreamer_humanoid_stand_0 itr #2999 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n",
      "2023-12-30 18:35:09.654959  | dreamer_humanoid_stand_0 itr #3999 saving snapshot...\n",
      "2023-12-30 18:35:09.714743  | dreamer_humanoid_stand_0 itr #3999 saved\n",
      "2023-12-30 18:35:09.721077  | -----------------------------  -----------\n",
      "2023-12-30 18:35:09.721659  | Diagnostics/NewCompletedTrajs     2\n",
      "2023-12-30 18:35:09.721951  | Diagnostics/StepsInTrajWindow  4000\n",
      "2023-12-30 18:35:09.722608  | Diagnostics/Iteration          3999\n",
      "2023-12-30 18:35:09.723100  | Diagnostics/CumTime (s)          32.8462\n",
      "2023-12-30 18:35:09.723692  | Diagnostics/CumSteps           4000\n",
      "2023-12-30 18:35:09.724292  | Diagnostics/CumCompletedTrajs     8\n",
      "2023-12-30 18:35:09.725083  | Diagnostics/CumUpdates            0\n",
      "2023-12-30 18:35:09.725499  | Diagnostics/StepsPerSecond      128.364\n",
      "2023-12-30 18:35:09.725964  | Diagnostics/UpdatesPerSecond      0\n",
      "2023-12-30 18:35:09.726410  | Diagnostics/ReplayRatio           0\n",
      "2023-12-30 18:35:09.726741  | Diagnostics/CumReplayRatio        0\n",
      "2023-12-30 18:35:09.727059  | Length/Average                  500\n",
      "2023-12-30 18:35:09.727370  | Length/Std                        0\n",
      "2023-12-30 18:35:09.727952  | Length/Median                   500\n",
      "2023-12-30 18:35:09.728356  | Length/Min                      500\n",
      "2023-12-30 18:35:09.728712  | Length/Max                      500\n",
      "2023-12-30 18:35:09.729042  | Return/Average                    5.08201\n",
      "2023-12-30 18:35:09.729393  | Return/Std                        3.46477\n",
      "2023-12-30 18:35:09.730032  | Return/Median                     4.73192\n",
      "2023-12-30 18:35:09.730438  | Return/Min                        0.281761\n",
      "2023-12-30 18:35:09.730870  | Return/Max                       10.0058\n",
      "2023-12-30 18:35:09.731422  | NonzeroRewards/Average          500\n",
      "2023-12-30 18:35:09.731794  | NonzeroRewards/Std                0\n",
      "2023-12-30 18:35:09.732102  | NonzeroRewards/Median           500\n",
      "2023-12-30 18:35:09.732596  | NonzeroRewards/Min              500\n",
      "2023-12-30 18:35:09.732996  | NonzeroRewards/Max              500\n",
      "2023-12-30 18:35:09.733303  | DiscountedReturn/Average          4.97114\n",
      "2023-12-30 18:35:09.733774  | DiscountedReturn/Std              3.37524\n",
      "2023-12-30 18:35:09.734183  | DiscountedReturn/Median           4.63134\n",
      "2023-12-30 18:35:09.734551  | DiscountedReturn/Min              0.277694\n",
      "2023-12-30 18:35:09.735265  | DiscountedReturn/Max              9.74608\n",
      "2023-12-30 18:35:09.735728  | loss/Average                    nan\n",
      "2023-12-30 18:35:09.736393  | loss/Std                        nan\n",
      "2023-12-30 18:35:09.736952  | loss/Median                     nan\n",
      "2023-12-30 18:35:09.737522  | loss/Min                        nan\n",
      "2023-12-30 18:35:09.738046  | loss/Max                        nan\n",
      "2023-12-30 18:35:09.738478  | grad_norm_model/Average         nan\n",
      "2023-12-30 18:35:09.738897  | grad_norm_model/Std             nan\n",
      "2023-12-30 18:35:09.739301  | grad_norm_model/Median          nan\n",
      "2023-12-30 18:35:09.739706  | grad_norm_model/Min             nan\n",
      "2023-12-30 18:35:09.740119  | grad_norm_model/Max             nan\n",
      "2023-12-30 18:35:09.740531  | grad_norm_actor/Average         nan\n",
      "2023-12-30 18:35:09.740972  | grad_norm_actor/Std             nan\n",
      "2023-12-30 18:35:09.742229  | grad_norm_actor/Median          nan\n",
      "2023-12-30 18:35:09.742669  | grad_norm_actor/Min             nan\n",
      "2023-12-30 18:35:09.743326  | grad_norm_actor/Max             nan\n",
      "2023-12-30 18:35:09.743758  | grad_norm_value/Average         nan\n",
      "2023-12-30 18:35:09.744047  | grad_norm_value/Std             nan\n",
      "2023-12-30 18:35:09.744501  | grad_norm_value/Median          nan\n",
      "2023-12-30 18:35:09.744894  | grad_norm_value/Min             nan\n",
      "2023-12-30 18:35:09.745258  | grad_norm_value/Max             nan\n",
      "2023-12-30 18:35:09.745627  | model_loss/Average              nan\n",
      "2023-12-30 18:35:09.745930  | model_loss/Std                  nan\n",
      "2023-12-30 18:35:09.746272  | model_loss/Median               nan\n",
      "2023-12-30 18:35:09.746593  | model_loss/Min                  nan\n",
      "2023-12-30 18:35:09.747213  | model_loss/Max                  nan\n",
      "2023-12-30 18:35:09.747533  | actor_loss/Average              nan\n",
      "2023-12-30 18:35:09.747973  | actor_loss/Std                  nan\n",
      "2023-12-30 18:35:09.748309  | actor_loss/Median               nan\n",
      "2023-12-30 18:35:09.748732  | actor_loss/Min                  nan\n",
      "2023-12-30 18:35:09.748986  | actor_loss/Max                  nan\n",
      "2023-12-30 18:35:09.749364  | value_loss/Average              nan\n",
      "2023-12-30 18:35:09.749633  | value_loss/Std                  nan\n",
      "2023-12-30 18:35:09.750156  | value_loss/Median               nan\n",
      "2023-12-30 18:35:09.750493  | value_loss/Min                  nan\n",
      "2023-12-30 18:35:09.750830  | value_loss/Max                  nan\n",
      "2023-12-30 18:35:09.751167  | prior_entropy/Average           nan\n",
      "2023-12-30 18:35:09.751502  | prior_entropy/Std               nan\n",
      "2023-12-30 18:35:09.751835  | prior_entropy/Median            nan\n",
      "2023-12-30 18:35:09.752202  | prior_entropy/Min               nan\n",
      "2023-12-30 18:35:09.752562  | prior_entropy/Max               nan\n",
      "2023-12-30 18:35:09.752938  | post_entropy/Average            nan\n",
      "2023-12-30 18:35:09.753241  | post_entropy/Std                nan\n",
      "2023-12-30 18:35:09.753656  | post_entropy/Median             nan\n",
      "2023-12-30 18:35:09.753946  | post_entropy/Min                nan\n",
      "2023-12-30 18:35:09.754355  | post_entropy/Max                nan\n",
      "2023-12-30 18:35:09.754698  | divergence/Average              nan\n",
      "2023-12-30 18:35:09.755055  | divergence/Std                  nan\n",
      "2023-12-30 18:35:09.755363  | divergence/Median               nan\n",
      "2023-12-30 18:35:09.755804  | divergence/Min                  nan\n",
      "2023-12-30 18:35:09.756186  | divergence/Max                  nan\n",
      "2023-12-30 18:35:09.756557  | reward_loss/Average             nan\n",
      "2023-12-30 18:35:09.756947  | reward_loss/Std                 nan\n",
      "2023-12-30 18:35:09.757479  | reward_loss/Median              nan\n",
      "2023-12-30 18:35:09.757872  | reward_loss/Min                 nan\n",
      "2023-12-30 18:35:09.758326  | reward_loss/Max                 nan\n",
      "2023-12-30 18:35:09.758946  | image_loss/Average              nan\n",
      "2023-12-30 18:35:09.759242  | image_loss/Std                  nan\n",
      "2023-12-30 18:35:09.759530  | image_loss/Median               nan\n",
      "2023-12-30 18:35:09.760014  | image_loss/Min                  nan\n",
      "2023-12-30 18:35:09.760363  | image_loss/Max                  nan\n",
      "2023-12-30 18:35:09.760771  | pcont_loss/Average              nan\n",
      "2023-12-30 18:35:09.761039  | pcont_loss/Std                  nan\n",
      "2023-12-30 18:35:09.761457  | pcont_loss/Median               nan\n",
      "2023-12-30 18:35:09.761960  | pcont_loss/Min                  nan\n",
      "2023-12-30 18:35:09.762553  | pcont_loss/Max                  nan\n",
      "2023-12-30 18:35:09.763015  | -----------------------------  -----------\n",
      "2023-12-30 18:35:09.763870  | dreamer_humanoid_stand_0 itr #3999 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n",
      "2023-12-30 18:35:17.505285  | dreamer_humanoid_stand_0 itr #4999 saving snapshot...\n",
      "2023-12-30 18:35:17.552806  | dreamer_humanoid_stand_0 itr #4999 saved\n",
      "2023-12-30 18:35:17.561402  | -----------------------------  -----------\n",
      "2023-12-30 18:35:17.562043  | Diagnostics/NewCompletedTrajs     2\n",
      "2023-12-30 18:35:17.562482  | Diagnostics/StepsInTrajWindow  5000\n",
      "2023-12-30 18:35:17.562893  | Diagnostics/Iteration          4999\n",
      "2023-12-30 18:35:17.563290  | Diagnostics/CumTime (s)          40.6846\n",
      "2023-12-30 18:35:17.564263  | Diagnostics/CumSteps           5000\n",
      "2023-12-30 18:35:17.564614  | Diagnostics/CumCompletedTrajs    10\n",
      "2023-12-30 18:35:17.565028  | Diagnostics/CumUpdates            0\n",
      "2023-12-30 18:35:17.565638  | Diagnostics/StepsPerSecond      127.577\n",
      "2023-12-30 18:35:17.565999  | Diagnostics/UpdatesPerSecond      0\n",
      "2023-12-30 18:35:17.566346  | Diagnostics/ReplayRatio           0\n",
      "2023-12-30 18:35:17.566938  | Diagnostics/CumReplayRatio        0\n",
      "2023-12-30 18:35:17.567380  | Length/Average                  500\n",
      "2023-12-30 18:35:17.567777  | Length/Std                        0\n",
      "2023-12-30 18:35:17.568477  | Length/Median                   500\n",
      "2023-12-30 18:35:17.569014  | Length/Min                      500\n",
      "2023-12-30 18:35:17.569721  | Length/Max                      500\n",
      "2023-12-30 18:35:17.570200  | Return/Average                    5.57673\n",
      "2023-12-30 18:35:17.570870  | Return/Std                        3.323\n",
      "2023-12-30 18:35:17.571278  | Return/Median                     5.76526\n",
      "2023-12-30 18:35:17.571623  | Return/Min                        0.281761\n",
      "2023-12-30 18:35:17.571929  | Return/Max                       10.0058\n",
      "2023-12-30 18:35:17.572529  | NonzeroRewards/Average          500\n",
      "2023-12-30 18:35:17.572871  | NonzeroRewards/Std                0\n",
      "2023-12-30 18:35:17.573413  | NonzeroRewards/Median           500\n",
      "2023-12-30 18:35:17.573913  | NonzeroRewards/Min              500\n",
      "2023-12-30 18:35:17.574206  | NonzeroRewards/Max              500\n",
      "2023-12-30 18:35:17.574674  | DiscountedReturn/Average          5.44888\n",
      "2023-12-30 18:35:17.575084  | DiscountedReturn/Std              3.2352\n",
      "2023-12-30 18:35:17.575389  | DiscountedReturn/Median           5.6207\n",
      "2023-12-30 18:35:17.575777  | DiscountedReturn/Min              0.277694\n",
      "2023-12-30 18:35:17.576651  | DiscountedReturn/Max              9.74608\n",
      "2023-12-30 18:35:17.576992  | loss/Average                    nan\n",
      "2023-12-30 18:35:17.577344  | loss/Std                        nan\n",
      "2023-12-30 18:35:17.578009  | loss/Median                     nan\n",
      "2023-12-30 18:35:17.578718  | loss/Min                        nan\n",
      "2023-12-30 18:35:17.579172  | loss/Max                        nan\n",
      "2023-12-30 18:35:17.579686  | grad_norm_model/Average         nan\n",
      "2023-12-30 18:35:17.580273  | grad_norm_model/Std             nan\n",
      "2023-12-30 18:35:17.580833  | grad_norm_model/Median          nan\n",
      "2023-12-30 18:35:17.581317  | grad_norm_model/Min             nan\n",
      "2023-12-30 18:35:17.581839  | grad_norm_model/Max             nan\n",
      "2023-12-30 18:35:17.582183  | grad_norm_actor/Average         nan\n",
      "2023-12-30 18:35:17.582634  | grad_norm_actor/Std             nan\n",
      "2023-12-30 18:35:17.582929  | grad_norm_actor/Median          nan\n",
      "2023-12-30 18:35:17.583216  | grad_norm_actor/Min             nan\n",
      "2023-12-30 18:35:17.583763  | grad_norm_actor/Max             nan\n",
      "2023-12-30 18:35:17.584075  | grad_norm_value/Average         nan\n",
      "2023-12-30 18:35:17.584376  | grad_norm_value/Std             nan\n",
      "2023-12-30 18:35:17.584704  | grad_norm_value/Median          nan\n",
      "2023-12-30 18:35:17.585074  | grad_norm_value/Min             nan\n",
      "2023-12-30 18:35:17.586013  | grad_norm_value/Max             nan\n",
      "2023-12-30 18:35:17.586682  | model_loss/Average              nan\n",
      "2023-12-30 18:35:17.587195  | model_loss/Std                  nan\n",
      "2023-12-30 18:35:17.587888  | model_loss/Median               nan\n",
      "2023-12-30 18:35:17.588303  | model_loss/Min                  nan\n",
      "2023-12-30 18:35:17.588686  | model_loss/Max                  nan\n",
      "2023-12-30 18:35:17.589049  | actor_loss/Average              nan\n",
      "2023-12-30 18:35:17.589343  | actor_loss/Std                  nan\n",
      "2023-12-30 18:35:17.589716  | actor_loss/Median               nan\n",
      "2023-12-30 18:35:17.590664  | actor_loss/Min                  nan\n",
      "2023-12-30 18:35:17.591113  | actor_loss/Max                  nan\n",
      "2023-12-30 18:35:17.591576  | value_loss/Average              nan\n",
      "2023-12-30 18:35:17.592390  | value_loss/Std                  nan\n",
      "2023-12-30 18:35:17.592872  | value_loss/Median               nan\n",
      "2023-12-30 18:35:17.593388  | value_loss/Min                  nan\n",
      "2023-12-30 18:35:17.593971  | value_loss/Max                  nan\n",
      "2023-12-30 18:35:17.594812  | prior_entropy/Average           nan\n",
      "2023-12-30 18:35:17.595373  | prior_entropy/Std               nan\n",
      "2023-12-30 18:35:17.595835  | prior_entropy/Median            nan\n",
      "2023-12-30 18:35:17.596326  | prior_entropy/Min               nan\n",
      "2023-12-30 18:35:17.596769  | prior_entropy/Max               nan\n",
      "2023-12-30 18:35:17.597245  | post_entropy/Average            nan\n",
      "2023-12-30 18:35:17.597589  | post_entropy/Std                nan\n",
      "2023-12-30 18:35:17.598190  | post_entropy/Median             nan\n",
      "2023-12-30 18:35:17.598567  | post_entropy/Min                nan\n",
      "2023-12-30 18:35:17.598997  | post_entropy/Max                nan\n",
      "2023-12-30 18:35:17.599510  | divergence/Average              nan\n",
      "2023-12-30 18:35:17.599868  | divergence/Std                  nan\n",
      "2023-12-30 18:35:17.600427  | divergence/Median               nan\n",
      "2023-12-30 18:35:17.601033  | divergence/Min                  nan\n",
      "2023-12-30 18:35:17.601535  | divergence/Max                  nan\n",
      "2023-12-30 18:35:17.602120  | reward_loss/Average             nan\n",
      "2023-12-30 18:35:17.602711  | reward_loss/Std                 nan\n",
      "2023-12-30 18:35:17.603318  | reward_loss/Median              nan\n",
      "2023-12-30 18:35:17.603843  | reward_loss/Min                 nan\n",
      "2023-12-30 18:35:17.604297  | reward_loss/Max                 nan\n",
      "2023-12-30 18:35:17.604740  | image_loss/Average              nan\n",
      "2023-12-30 18:35:17.605681  | image_loss/Std                  nan\n",
      "2023-12-30 18:35:17.606351  | image_loss/Median               nan\n",
      "2023-12-30 18:35:17.606997  | image_loss/Min                  nan\n",
      "2023-12-30 18:35:17.607593  | image_loss/Max                  nan\n",
      "2023-12-30 18:35:17.608366  | pcont_loss/Average              nan\n",
      "2023-12-30 18:35:17.608880  | pcont_loss/Std                  nan\n",
      "2023-12-30 18:35:17.609579  | pcont_loss/Median               nan\n",
      "2023-12-30 18:35:17.610090  | pcont_loss/Min                  nan\n",
      "2023-12-30 18:35:17.610640  | pcont_loss/Max                  nan\n",
      "2023-12-30 18:35:17.611101  | -----------------------------  -----------\n",
      "2023-12-30 18:35:17.611646  | dreamer_humanoid_stand_0 itr #4999 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imagination:   0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2500x230 and 1024x1024)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/eddy/Projects/RL_project/logs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mbuild_and_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhumanoid_stand\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_ID\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcuda_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 60\u001b[0m, in \u001b[0;36mbuild_and_train\u001b[0;34m(log_dir, game, run_ID, cuda_idx, eval, save_model, load_model_path)\u001b[0m\n\u001b[1;32m     50\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdreamer_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m game\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m logger_context(\n\u001b[1;32m     52\u001b[0m     log_dir,\n\u001b[1;32m     53\u001b[0m     run_ID,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     use_summary_writer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     59\u001b[0m ):\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/RL_project/rlpyt/rlpyt/runners/minibatch_rl.py:261\u001b[0m, in \u001b[0;36mMinibatchRl.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m samples, traj_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39mobtain_samples(itr)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mtrain_mode(itr)\n\u001b[0;32m--> 261\u001b[0m opt_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_diagnostics(itr, traj_infos, opt_info)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (itr \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_interval_itrs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Projects/RL_project/algorithm.py:219\u001b[0m, in \u001b[0;36mDreamer.optimize_agent\u001b[0;34m(self, itr, samples, sampler_itr)\u001b[0m\n\u001b[1;32m    215\u001b[0m samples_from_replay \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer\u001b[38;5;241m.\u001b[39msample_batch(\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_length\n\u001b[1;32m    217\u001b[0m )\n\u001b[1;32m    218\u001b[0m buffed_samples \u001b[38;5;241m=\u001b[39m buffer_to(samples_from_replay, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 219\u001b[0m model_loss, actor_loss, value_loss, loss_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffed_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Projects/RL_project/algorithm.py:308\u001b[0m, in \u001b[0;36mDreamer.loss\u001b[0;34m(self, samples, sample_itr, opt_itr)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# Flatten our data (so first dimension is batch_t * batch_b = batch_size)\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# since we're going to do a new rollout starting from each state visited in each batch.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# Compute losses for each component of the model\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# Model Loss\u001b[39;00m\n\u001b[1;32m    307\u001b[0m feat \u001b[38;5;241m=\u001b[39m get_feat(post)\n\u001b[0;32m--> 308\u001b[0m image_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m reward_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mreward_model(feat)\n\u001b[1;32m    310\u001b[0m reward_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmean(reward_pred\u001b[38;5;241m.\u001b[39mlog_prob(reward))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/RL_project/models/Observation.py:108\u001b[0m, in \u001b[0;36mObservationDec.forward\u001b[0;34m(self, encoding)\u001b[0m\n\u001b[1;32m    106\u001b[0m squeezed_size \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mprod(batch_shape)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    107\u001b[0m x \u001b[38;5;241m=\u001b[39m encoding\u001b[38;5;241m.\u001b[39mreshape(squeezed_size, embed_size)\n\u001b[0;32m--> 108\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(x, (squeezed_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_shape))\n\u001b[1;32m    110\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2500x230 and 1024x1024)"
     ]
    }
   ],
   "source": [
    "log_dir = os.path.abspath('/home/eddy/Projects/RL_project/logs')\n",
    "\n",
    "build_and_train(\n",
    "        log_dir,\n",
    "        game=\"humanoid_stand\",\n",
    "        run_ID=0,\n",
    "        cuda_idx=0,\n",
    "        eval=False,\n",
    "        save_model=\"last\",\n",
    "        load_model_path=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
