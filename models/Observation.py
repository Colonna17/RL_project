#OBSERVATION MODEL IS A TRANSPOSED CNN
import numpy as np
import torch
import torch.distributions as td
import torch.nn as nn


"""
Observation needs two different models. One is used to transform input images from the scene into latent encoding.
The second one does the opposite action, taking one latent encoding generated by agent's dreaming and decoding it 
back into an image. For this part a transposed CNN is used as stated in the paper
"""

class ObservationEnc(nn.Module):
    def __init__(self, stride_sz, hidden_sz = 32, kernel_sz = 5, img_size = (3,64,64)):
        super().__init__()
        self.hidden_sz = hidden_sz
        stride = 2
        k_size = 4
        self.dim1 = img_size(0)
        self.dim2 = img_size(1)
        self.conv1 = nn.Conv2d(self.dim1, hidden_sz, k_size, stride)
        self.conv2 = nn.Conv2d(hidden_sz, hidden_sz *2, k_size, stride)
        self.conv3 = nn.Conv2d(self.dim1*2, hidden_sz*4, k_size, stride)
        self.conv4 = nn.Conv2d(self.dim1*4, hidden_sz*8, k_size, stride)
        self.activation = nn.ReLU   

    def forward(self, input):
        batch_shape = input.shape[0]
        img_shape = input.shape[1:]
        embed = self.conv1(input.reshape(-1, *img_shape))
        embed = self.activation(embed)
        embed = self.conv2(input.reshape(-1, *img_shape))
        embed = self.activation(embed)
        embed = self.conv3(input.reshape(-1, *img_shape))
        embed = self.activation(embed)
        embed = self.conv4(input.reshape(-1, *img_shape))
        embed = self.activation(embed)
        embed = torch.reshape(embed, (*batch_shape, -1))
        return embed


class ObservationDec(nn.Module):
    def __init__(self, hidden_sz, stride_sz, kernel_sz = 5, img_size = (3,64,64)):
        super().__init__()
        self.hidden_sz = hidden_sz
        stride = 2
        k_size = 4
        self.dim1 = img_size(0)
        self.dim2 = img_size(1)
        self.conv1 = nn.Conv2d(self.dim1, hidden_sz, k_size, stride)
        self.conv2 = nn.Conv2d(hidden_sz, hidden_sz *2, k_size, stride)
        self.conv3 = nn.Conv2d(self.dim1*2, hidden_sz*4, k_size, stride)
        self.conv4 = nn.Conv2d(self.dim1*4, hidden_sz*8, k_size, stride)
        self.activation = nn.ReLU   




