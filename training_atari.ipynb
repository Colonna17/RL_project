{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-07 16:11:22.717921: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-07 16:11:23.305095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "\n",
    "from rlpyt.runners.minibatch_rl import MinibatchRlEval, MinibatchRl\n",
    "from rlpyt.samplers.serial.sampler import SerialSampler\n",
    "from rlpyt.utils.logging.context import logger_context\n",
    "from rlpyt.envs.atari.atari_env import AtariTrajInfo\n",
    "\n",
    "from dreamer_agent import AtariDreamerAgent\n",
    "from algorithm import Dreamer\n",
    "from envs.atari import AtariEnv\n",
    "from envs.wrapper import make_wapper\n",
    "from envs.one_hot import OneHotAction\n",
    "from envs.time_limit import TimeLimit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def build_and_train(\n",
    "    log_dir,\n",
    "    game=\"pong\",\n",
    "    run_ID=0,\n",
    "    cuda_idx=None,\n",
    "    eval=False,\n",
    "    save_model=\"last\",\n",
    "    load_model_path=None,\n",
    "):\n",
    "    params = torch.load(load_model_path) if load_model_path else {}\n",
    "    agent_state_dict = params.get(\"agent_state_dict\")\n",
    "    optimizer_state_dict = params.get(\"optimizer_state_dict\")\n",
    "\n",
    "    action_repeat = 2\n",
    "    env_kwargs = dict(\n",
    "        name=game,\n",
    "        action_repeat=action_repeat,\n",
    "        size=(64, 64),\n",
    "        grayscale=False,\n",
    "        life_done=True,\n",
    "        sticky_actions=False,\n",
    "    )\n",
    "    factory_method = make_wapper(\n",
    "        AtariEnv,\n",
    "        [OneHotAction, TimeLimit],\n",
    "        [dict(), dict(duration=1000 / action_repeat)],\n",
    "    )\n",
    "    sampler = SerialSampler(\n",
    "        EnvCls=factory_method,\n",
    "        TrajInfoCls=AtariTrajInfo,  # default traj info + GameScore\n",
    "        env_kwargs=env_kwargs,\n",
    "        eval_env_kwargs=env_kwargs,\n",
    "        batch_T=1,\n",
    "        batch_B=1,\n",
    "        max_decorrelation_steps=0,\n",
    "        eval_n_envs=10,\n",
    "        eval_max_steps=int(10e3),\n",
    "        eval_max_trajectories=5,\n",
    "    )\n",
    "    algo = Dreamer(\n",
    "        horizon=10,\n",
    "        kl_scale=0.1,\n",
    "        use_pcont=True,\n",
    "        initial_optim_state_dict=optimizer_state_dict,\n",
    "    )\n",
    "    agent = AtariDreamerAgent(\n",
    "        train_noise=0.4,\n",
    "        eval_noise=0,\n",
    "        expl_type=\"epsilon_greedy\",\n",
    "        expl_min=0.1,\n",
    "        expl_decay=2000 / 0.3,\n",
    "        initial_model_state_dict=agent_state_dict,\n",
    "        model_kwargs=dict(use_pcont=True),\n",
    "    )\n",
    "    runner_cls = MinibatchRlEval if eval else MinibatchRl\n",
    "    runner = runner_cls(\n",
    "        algo=algo,\n",
    "        agent=agent,\n",
    "        sampler=sampler,\n",
    "        n_steps=5e6,\n",
    "        log_interval_steps=1e3,\n",
    "        affinity=dict(cuda_idx=cuda_idx),\n",
    "    )\n",
    "    config = dict(game=game)\n",
    "    name = \"dreamer_\" + game\n",
    "    with logger_context(\n",
    "        log_dir,\n",
    "        run_ID,\n",
    "        name,\n",
    "        config,\n",
    "        snapshot_mode=save_model,\n",
    "        override_prefix=True,\n",
    "        use_summary_writer=True,\n",
    "    ):\n",
    "        runner.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 16:11:24.031908  | dreamer_assault_0 Runner  master CPU affinity: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11].\n",
      "2024-01-07 16:11:24.032600  | dreamer_assault_0 Runner  master Torch threads: 6.\n",
      "\u001b[32musing seed 6944\u001b[0m\n",
      "2024-01-07 16:11:25.489589  | dreamer_assault_0 Sampler decorrelating envs, max steps: 0\n",
      "2024-01-07 16:11:25.490290  | dreamer_assault_0 Serial Sampler initialized.\n",
      "2024-01-07 16:11:25.490614  | dreamer_assault_0 Running 5000000 iterations of minibatch RL.\n",
      "2024-01-07 16:11:26.247878  | dreamer_assault_0 Initialized agent model on device: cuda:0.\n",
      "DAI CHE SIAMO VICINIIIIIIII\n",
      "size passato a SequenceNStepReturnBuffer = 300000\n",
      "2024-01-07 16:11:26.249539  | dreamer_assault_0 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eddy/.local/lib/python3.10/site-packages/torch/optim/adam.py:33: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super().__init__(params, defaults)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 16:11:30.648241  | dreamer_assault_0 itr #999 saving snapshot...\n",
      "2024-01-07 16:11:30.683151  | dreamer_assault_0 itr #999 saved\n",
      "2024-01-07 16:11:30.689410  | -----------------------------  -----------\n",
      "2024-01-07 16:11:30.689923  | Diagnostics/NewCompletedTrajs     3\n",
      "2024-01-07 16:11:30.690231  | Diagnostics/StepsInTrajWindow   915\n",
      "2024-01-07 16:11:30.690590  | Diagnostics/Iteration           999\n",
      "2024-01-07 16:11:30.691053  | Diagnostics/CumTime (s)           4.43372\n",
      "2024-01-07 16:11:30.692392  | Diagnostics/CumSteps           1000\n",
      "2024-01-07 16:11:30.692868  | Diagnostics/CumCompletedTrajs     3\n",
      "2024-01-07 16:11:30.693276  | Diagnostics/CumUpdates            0\n",
      "2024-01-07 16:11:30.694197  | Diagnostics/StepsPerSecond      225.544\n",
      "2024-01-07 16:11:30.694667  | Diagnostics/UpdatesPerSecond      0\n",
      "2024-01-07 16:11:30.694997  | Diagnostics/ReplayRatio           0\n",
      "2024-01-07 16:11:30.695412  | Diagnostics/CumReplayRatio        0\n",
      "2024-01-07 16:11:30.695902  | Length/Average                  305\n",
      "2024-01-07 16:11:30.696743  | Length/Std                       39.4208\n",
      "2024-01-07 16:11:30.697104  | Length/Median                   290\n",
      "2024-01-07 16:11:30.697564  | Length/Min                      266\n",
      "2024-01-07 16:11:30.698114  | Length/Max                      359\n",
      "2024-01-07 16:11:30.698506  | Return/Average                   98\n",
      "2024-01-07 16:11:30.699043  | Return/Std                        9.89949\n",
      "2024-01-07 16:11:30.699449  | Return/Median                   105\n",
      "2024-01-07 16:11:30.699747  | Return/Min                       84\n",
      "2024-01-07 16:11:30.700211  | Return/Max                      105\n",
      "2024-01-07 16:11:30.700618  | NonzeroRewards/Average            4.66667\n",
      "2024-01-07 16:11:30.700973  | NonzeroRewards/Std                0.471405\n",
      "2024-01-07 16:11:30.701411  | NonzeroRewards/Median             5\n",
      "2024-01-07 16:11:30.701793  | NonzeroRewards/Min                4\n",
      "2024-01-07 16:11:30.702283  | NonzeroRewards/Max                5\n",
      "2024-01-07 16:11:30.702701  | DiscountedReturn/Average         39.5222\n",
      "2024-01-07 16:11:30.703111  | DiscountedReturn/Std              7.58175\n",
      "2024-01-07 16:11:30.703736  | DiscountedReturn/Median          37.1933\n",
      "2024-01-07 16:11:30.704074  | DiscountedReturn/Min             31.6226\n",
      "2024-01-07 16:11:30.704585  | DiscountedReturn/Max             49.7507\n",
      "2024-01-07 16:11:30.704949  | GameScore/Average                98\n",
      "2024-01-07 16:11:30.705464  | GameScore/Std                     9.89949\n",
      "2024-01-07 16:11:30.705906  | GameScore/Median                105\n",
      "2024-01-07 16:11:30.706247  | GameScore/Min                    84\n",
      "2024-01-07 16:11:30.706558  | GameScore/Max                   105\n",
      "2024-01-07 16:11:30.707113  | loss/Average                    nan\n",
      "2024-01-07 16:11:30.707561  | loss/Std                        nan\n",
      "2024-01-07 16:11:30.707974  | loss/Median                     nan\n",
      "2024-01-07 16:11:30.708411  | loss/Min                        nan\n",
      "2024-01-07 16:11:30.709130  | loss/Max                        nan\n",
      "2024-01-07 16:11:30.709513  | grad_norm_model/Average         nan\n",
      "2024-01-07 16:11:30.709959  | grad_norm_model/Std             nan\n",
      "2024-01-07 16:11:30.710346  | grad_norm_model/Median          nan\n",
      "2024-01-07 16:11:30.710789  | grad_norm_model/Min             nan\n",
      "2024-01-07 16:11:30.711191  | grad_norm_model/Max             nan\n",
      "2024-01-07 16:11:30.711519  | grad_norm_actor/Average         nan\n",
      "2024-01-07 16:11:30.711875  | grad_norm_actor/Std             nan\n",
      "2024-01-07 16:11:30.712533  | grad_norm_actor/Median          nan\n",
      "2024-01-07 16:11:30.712816  | grad_norm_actor/Min             nan\n",
      "2024-01-07 16:11:30.713240  | grad_norm_actor/Max             nan\n",
      "2024-01-07 16:11:30.713628  | grad_norm_value/Average         nan\n",
      "2024-01-07 16:11:30.714071  | grad_norm_value/Std             nan\n",
      "2024-01-07 16:11:30.714429  | grad_norm_value/Median          nan\n",
      "2024-01-07 16:11:30.714872  | grad_norm_value/Min             nan\n",
      "2024-01-07 16:11:30.715285  | grad_norm_value/Max             nan\n",
      "2024-01-07 16:11:30.715800  | model_loss/Average              nan\n",
      "2024-01-07 16:11:30.716222  | model_loss/Std                  nan\n",
      "2024-01-07 16:11:30.716646  | model_loss/Median               nan\n",
      "2024-01-07 16:11:30.717103  | model_loss/Min                  nan\n",
      "2024-01-07 16:11:30.717502  | model_loss/Max                  nan\n",
      "2024-01-07 16:11:30.717895  | actor_loss/Average              nan\n",
      "2024-01-07 16:11:30.718192  | actor_loss/Std                  nan\n",
      "2024-01-07 16:11:30.718619  | actor_loss/Median               nan\n",
      "2024-01-07 16:11:30.718974  | actor_loss/Min                  nan\n",
      "2024-01-07 16:11:30.719404  | actor_loss/Max                  nan\n",
      "2024-01-07 16:11:30.719698  | value_loss/Average              nan\n",
      "2024-01-07 16:11:30.720120  | value_loss/Std                  nan\n",
      "2024-01-07 16:11:30.720499  | value_loss/Median               nan\n",
      "2024-01-07 16:11:30.720887  | value_loss/Min                  nan\n",
      "2024-01-07 16:11:30.721204  | value_loss/Max                  nan\n",
      "2024-01-07 16:11:30.721644  | prior_entropy/Average           nan\n",
      "2024-01-07 16:11:30.722078  | prior_entropy/Std               nan\n",
      "2024-01-07 16:11:30.722470  | prior_entropy/Median            nan\n",
      "2024-01-07 16:11:30.722762  | prior_entropy/Min               nan\n",
      "2024-01-07 16:11:30.723082  | prior_entropy/Max               nan\n",
      "2024-01-07 16:11:30.723576  | post_entropy/Average            nan\n",
      "2024-01-07 16:11:30.723869  | post_entropy/Std                nan\n",
      "2024-01-07 16:11:30.724182  | post_entropy/Median             nan\n",
      "2024-01-07 16:11:30.724785  | post_entropy/Min                nan\n",
      "2024-01-07 16:11:30.725237  | post_entropy/Max                nan\n",
      "2024-01-07 16:11:30.725631  | divergence/Average              nan\n",
      "2024-01-07 16:11:30.725987  | divergence/Std                  nan\n",
      "2024-01-07 16:11:30.726436  | divergence/Median               nan\n",
      "2024-01-07 16:11:30.726860  | divergence/Min                  nan\n",
      "2024-01-07 16:11:30.727350  | divergence/Max                  nan\n",
      "2024-01-07 16:11:30.727847  | reward_loss/Average             nan\n",
      "2024-01-07 16:11:30.728278  | reward_loss/Std                 nan\n",
      "2024-01-07 16:11:30.728830  | reward_loss/Median              nan\n",
      "2024-01-07 16:11:30.729277  | reward_loss/Min                 nan\n",
      "2024-01-07 16:11:30.729869  | reward_loss/Max                 nan\n",
      "2024-01-07 16:11:30.730230  | image_loss/Average              nan\n",
      "2024-01-07 16:11:30.730573  | image_loss/Std                  nan\n",
      "2024-01-07 16:11:30.730988  | image_loss/Median               nan\n",
      "2024-01-07 16:11:30.731388  | image_loss/Min                  nan\n",
      "2024-01-07 16:11:30.731718  | image_loss/Max                  nan\n",
      "2024-01-07 16:11:30.732341  | pcont_loss/Average              nan\n",
      "2024-01-07 16:11:30.732729  | pcont_loss/Std                  nan\n",
      "2024-01-07 16:11:30.733151  | pcont_loss/Median               nan\n",
      "2024-01-07 16:11:30.733558  | pcont_loss/Min                  nan\n",
      "2024-01-07 16:11:30.733970  | pcont_loss/Max                  nan\n",
      "2024-01-07 16:11:30.734450  | -----------------------------  -----------\n",
      "2024-01-07 16:11:30.735406  | dreamer_assault_0 itr #999 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n",
      "2024-01-07 16:11:34.561608  | dreamer_assault_0 itr #1999 saving snapshot...\n",
      "2024-01-07 16:11:34.623703  | dreamer_assault_0 itr #1999 saved\n",
      "2024-01-07 16:11:34.630006  | -----------------------------  ----------\n",
      "2024-01-07 16:11:34.630802  | Diagnostics/NewCompletedTrajs     4\n",
      "2024-01-07 16:11:34.631286  | Diagnostics/StepsInTrajWindow  1963\n",
      "2024-01-07 16:11:34.631782  | Diagnostics/Iteration          1999\n",
      "2024-01-07 16:11:34.632229  | Diagnostics/CumTime (s)           8.37451\n",
      "2024-01-07 16:11:34.632648  | Diagnostics/CumSteps           2000\n",
      "2024-01-07 16:11:34.633090  | Diagnostics/CumCompletedTrajs     7\n",
      "2024-01-07 16:11:34.633551  | Diagnostics/CumUpdates            0\n",
      "2024-01-07 16:11:34.634372  | Diagnostics/StepsPerSecond      253.756\n",
      "2024-01-07 16:11:34.634771  | Diagnostics/UpdatesPerSecond      0\n",
      "2024-01-07 16:11:34.635119  | Diagnostics/ReplayRatio           0\n",
      "2024-01-07 16:11:34.635566  | Diagnostics/CumReplayRatio        0\n",
      "2024-01-07 16:11:34.636060  | Length/Average                  280.429\n",
      "2024-01-07 16:11:34.636400  | Length/Std                       75.1795\n",
      "2024-01-07 16:11:34.636735  | Length/Median                   290\n",
      "2024-01-07 16:11:34.637159  | Length/Min                      123\n",
      "2024-01-07 16:11:34.637524  | Length/Max                      369\n",
      "2024-01-07 16:11:34.637905  | Return/Average                   84\n",
      "2024-01-07 16:11:34.638707  | Return/Std                       27.4955\n",
      "2024-01-07 16:11:34.639161  | Return/Median                    84\n",
      "2024-01-07 16:11:34.639495  | Return/Min                       21\n",
      "2024-01-07 16:11:34.640029  | Return/Max                      105\n",
      "2024-01-07 16:11:34.640337  | NonzeroRewards/Average            4\n",
      "2024-01-07 16:11:34.640762  | NonzeroRewards/Std                1.30931\n",
      "2024-01-07 16:11:34.641119  | NonzeroRewards/Median             4\n",
      "2024-01-07 16:11:34.641550  | NonzeroRewards/Min                1\n",
      "2024-01-07 16:11:34.641990  | NonzeroRewards/Max                5\n",
      "2024-01-07 16:11:34.642803  | DiscountedReturn/Average         32.3296\n",
      "2024-01-07 16:11:34.643355  | DiscountedReturn/Std             11.8544\n",
      "2024-01-07 16:11:34.643763  | DiscountedReturn/Median          31.8081\n",
      "2024-01-07 16:11:34.644171  | DiscountedReturn/Min              7.84275\n",
      "2024-01-07 16:11:34.644521  | DiscountedReturn/Max             49.7507\n",
      "2024-01-07 16:11:34.645120  | GameScore/Average                84\n",
      "2024-01-07 16:11:34.645429  | GameScore/Std                    27.4955\n",
      "2024-01-07 16:11:34.645746  | GameScore/Median                 84\n",
      "2024-01-07 16:11:34.646221  | GameScore/Min                    21\n",
      "2024-01-07 16:11:34.646489  | GameScore/Max                   105\n",
      "2024-01-07 16:11:34.646872  | loss/Average                    nan\n",
      "2024-01-07 16:11:34.647146  | loss/Std                        nan\n",
      "2024-01-07 16:11:34.647606  | loss/Median                     nan\n",
      "2024-01-07 16:11:34.648430  | loss/Min                        nan\n",
      "2024-01-07 16:11:34.648964  | loss/Max                        nan\n",
      "2024-01-07 16:11:34.649448  | grad_norm_model/Average         nan\n",
      "2024-01-07 16:11:34.650024  | grad_norm_model/Std             nan\n",
      "2024-01-07 16:11:34.651097  | grad_norm_model/Median          nan\n",
      "2024-01-07 16:11:34.651662  | grad_norm_model/Min             nan\n",
      "2024-01-07 16:11:34.652065  | grad_norm_model/Max             nan\n",
      "2024-01-07 16:11:34.652612  | grad_norm_actor/Average         nan\n",
      "2024-01-07 16:11:34.652990  | grad_norm_actor/Std             nan\n",
      "2024-01-07 16:11:34.653478  | grad_norm_actor/Median          nan\n",
      "2024-01-07 16:11:34.653886  | grad_norm_actor/Min             nan\n",
      "2024-01-07 16:11:34.654253  | grad_norm_actor/Max             nan\n",
      "2024-01-07 16:11:34.654633  | grad_norm_value/Average         nan\n",
      "2024-01-07 16:11:34.655522  | grad_norm_value/Std             nan\n",
      "2024-01-07 16:11:34.656040  | grad_norm_value/Median          nan\n",
      "2024-01-07 16:11:34.656652  | grad_norm_value/Min             nan\n",
      "2024-01-07 16:11:34.657273  | grad_norm_value/Max             nan\n",
      "2024-01-07 16:11:34.657743  | model_loss/Average              nan\n",
      "2024-01-07 16:11:34.658198  | model_loss/Std                  nan\n",
      "2024-01-07 16:11:34.658711  | model_loss/Median               nan\n",
      "2024-01-07 16:11:34.659150  | model_loss/Min                  nan\n",
      "2024-01-07 16:11:34.660215  | model_loss/Max                  nan\n",
      "2024-01-07 16:11:34.660868  | actor_loss/Average              nan\n",
      "2024-01-07 16:11:34.661339  | actor_loss/Std                  nan\n",
      "2024-01-07 16:11:34.661646  | actor_loss/Median               nan\n",
      "2024-01-07 16:11:34.662098  | actor_loss/Min                  nan\n",
      "2024-01-07 16:11:34.662621  | actor_loss/Max                  nan\n",
      "2024-01-07 16:11:34.662982  | value_loss/Average              nan\n",
      "2024-01-07 16:11:34.663292  | value_loss/Std                  nan\n",
      "2024-01-07 16:11:34.663585  | value_loss/Median               nan\n",
      "2024-01-07 16:11:34.663877  | value_loss/Min                  nan\n",
      "2024-01-07 16:11:34.664205  | value_loss/Max                  nan\n",
      "2024-01-07 16:11:34.664554  | prior_entropy/Average           nan\n",
      "2024-01-07 16:11:34.664833  | prior_entropy/Std               nan\n",
      "2024-01-07 16:11:34.665130  | prior_entropy/Median            nan\n",
      "2024-01-07 16:11:34.666326  | prior_entropy/Min               nan\n",
      "2024-01-07 16:11:34.666645  | prior_entropy/Max               nan\n",
      "2024-01-07 16:11:34.667131  | post_entropy/Average            nan\n",
      "2024-01-07 16:11:34.667620  | post_entropy/Std                nan\n",
      "2024-01-07 16:11:34.667987  | post_entropy/Median             nan\n",
      "2024-01-07 16:11:34.668376  | post_entropy/Min                nan\n",
      "2024-01-07 16:11:34.668841  | post_entropy/Max                nan\n",
      "2024-01-07 16:11:34.669257  | divergence/Average              nan\n",
      "2024-01-07 16:11:34.669665  | divergence/Std                  nan\n",
      "2024-01-07 16:11:34.670900  | divergence/Median               nan\n",
      "2024-01-07 16:11:34.671522  | divergence/Min                  nan\n",
      "2024-01-07 16:11:34.672128  | divergence/Max                  nan\n",
      "2024-01-07 16:11:34.672808  | reward_loss/Average             nan\n",
      "2024-01-07 16:11:34.673271  | reward_loss/Std                 nan\n",
      "2024-01-07 16:11:34.673855  | reward_loss/Median              nan\n",
      "2024-01-07 16:11:34.674578  | reward_loss/Min                 nan\n",
      "2024-01-07 16:11:34.674981  | reward_loss/Max                 nan\n",
      "2024-01-07 16:11:34.675535  | image_loss/Average              nan\n",
      "2024-01-07 16:11:34.676297  | image_loss/Std                  nan\n",
      "2024-01-07 16:11:34.676732  | image_loss/Median               nan\n",
      "2024-01-07 16:11:34.677108  | image_loss/Min                  nan\n",
      "2024-01-07 16:11:34.677611  | image_loss/Max                  nan\n",
      "2024-01-07 16:11:34.678101  | pcont_loss/Average              nan\n",
      "2024-01-07 16:11:34.678526  | pcont_loss/Std                  nan\n",
      "2024-01-07 16:11:34.679485  | pcont_loss/Median               nan\n",
      "2024-01-07 16:11:34.679850  | pcont_loss/Min                  nan\n",
      "2024-01-07 16:11:34.680354  | pcont_loss/Max                  nan\n",
      "2024-01-07 16:11:34.681088  | -----------------------------  ----------\n",
      "2024-01-07 16:11:34.681699  | dreamer_assault_0 itr #1999 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n",
      "2024-01-07 16:11:38.476538  | dreamer_assault_0 itr #2999 saving snapshot...\n",
      "2024-01-07 16:11:38.533213  | dreamer_assault_0 itr #2999 saved\n",
      "2024-01-07 16:11:38.539169  | -----------------------------  ----------\n",
      "2024-01-07 16:11:38.539668  | Diagnostics/NewCompletedTrajs     3\n",
      "2024-01-07 16:11:38.539995  | Diagnostics/StepsInTrajWindow  2800\n",
      "2024-01-07 16:11:38.540318  | Diagnostics/Iteration          2999\n",
      "2024-01-07 16:11:38.540685  | Diagnostics/CumTime (s)          12.2841\n",
      "2024-01-07 16:11:38.541026  | Diagnostics/CumSteps           3000\n",
      "2024-01-07 16:11:38.541375  | Diagnostics/CumCompletedTrajs    10\n",
      "2024-01-07 16:11:38.542543  | Diagnostics/CumUpdates            0\n",
      "2024-01-07 16:11:38.542855  | Diagnostics/StepsPerSecond      255.784\n",
      "2024-01-07 16:11:38.543195  | Diagnostics/UpdatesPerSecond      0\n",
      "2024-01-07 16:11:38.543635  | Diagnostics/ReplayRatio           0\n",
      "2024-01-07 16:11:38.544196  | Diagnostics/CumReplayRatio        0\n",
      "2024-01-07 16:11:38.544569  | Length/Average                  280\n",
      "2024-01-07 16:11:38.545037  | Length/Std                       63.4303\n",
      "2024-01-07 16:11:38.545412  | Length/Median                   280\n",
      "2024-01-07 16:11:38.545735  | Length/Min                      123\n",
      "2024-01-07 16:11:38.546112  | Length/Max                      369\n",
      "2024-01-07 16:11:38.546475  | Return/Average                   79.8\n",
      "2024-01-07 16:11:38.546784  | Return/Std                       24.49\n",
      "2024-01-07 16:11:38.547055  | Return/Median                    84\n",
      "2024-01-07 16:11:38.547534  | Return/Min                       21\n",
      "2024-01-07 16:11:38.547904  | Return/Max                      105\n",
      "2024-01-07 16:11:38.548228  | NonzeroRewards/Average            3.8\n",
      "2024-01-07 16:11:38.548522  | NonzeroRewards/Std                1.16619\n",
      "2024-01-07 16:11:38.548959  | NonzeroRewards/Median             4\n",
      "2024-01-07 16:11:38.549344  | NonzeroRewards/Min                1\n",
      "2024-01-07 16:11:38.549854  | NonzeroRewards/Max                5\n",
      "2024-01-07 16:11:38.550253  | DiscountedReturn/Average         29.3128\n",
      "2024-01-07 16:11:38.550767  | DiscountedReturn/Std             11.6092\n",
      "2024-01-07 16:11:38.551179  | DiscountedReturn/Median          31.7154\n",
      "2024-01-07 16:11:38.551486  | DiscountedReturn/Min              7.84275\n",
      "2024-01-07 16:11:38.551787  | DiscountedReturn/Max             49.7507\n",
      "2024-01-07 16:11:38.552495  | GameScore/Average                79.8\n",
      "2024-01-07 16:11:38.552881  | GameScore/Std                    24.49\n",
      "2024-01-07 16:11:38.553392  | GameScore/Median                 84\n",
      "2024-01-07 16:11:38.553751  | GameScore/Min                    21\n",
      "2024-01-07 16:11:38.554125  | GameScore/Max                   105\n",
      "2024-01-07 16:11:38.554714  | loss/Average                    nan\n",
      "2024-01-07 16:11:38.555063  | loss/Std                        nan\n",
      "2024-01-07 16:11:38.555491  | loss/Median                     nan\n",
      "2024-01-07 16:11:38.555774  | loss/Min                        nan\n",
      "2024-01-07 16:11:38.556062  | loss/Max                        nan\n",
      "2024-01-07 16:11:38.556332  | grad_norm_model/Average         nan\n",
      "2024-01-07 16:11:38.556645  | grad_norm_model/Std             nan\n",
      "2024-01-07 16:11:38.557266  | grad_norm_model/Median          nan\n",
      "2024-01-07 16:11:38.557786  | grad_norm_model/Min             nan\n",
      "2024-01-07 16:11:38.558211  | grad_norm_model/Max             nan\n",
      "2024-01-07 16:11:38.558786  | grad_norm_actor/Average         nan\n",
      "2024-01-07 16:11:38.559371  | grad_norm_actor/Std             nan\n",
      "2024-01-07 16:11:38.559716  | grad_norm_actor/Median          nan\n",
      "2024-01-07 16:11:38.560149  | grad_norm_actor/Min             nan\n",
      "2024-01-07 16:11:38.560602  | grad_norm_actor/Max             nan\n",
      "2024-01-07 16:11:38.560931  | grad_norm_value/Average         nan\n",
      "2024-01-07 16:11:38.561572  | grad_norm_value/Std             nan\n",
      "2024-01-07 16:11:38.562233  | grad_norm_value/Median          nan\n",
      "2024-01-07 16:11:38.562847  | grad_norm_value/Min             nan\n",
      "2024-01-07 16:11:38.563342  | grad_norm_value/Max             nan\n",
      "2024-01-07 16:11:38.563742  | model_loss/Average              nan\n",
      "2024-01-07 16:11:38.564141  | model_loss/Std                  nan\n",
      "2024-01-07 16:11:38.564554  | model_loss/Median               nan\n",
      "2024-01-07 16:11:38.564981  | model_loss/Min                  nan\n",
      "2024-01-07 16:11:38.565422  | model_loss/Max                  nan\n",
      "2024-01-07 16:11:38.565989  | actor_loss/Average              nan\n",
      "2024-01-07 16:11:38.566956  | actor_loss/Std                  nan\n",
      "2024-01-07 16:11:38.567482  | actor_loss/Median               nan\n",
      "2024-01-07 16:11:38.567766  | actor_loss/Min                  nan\n",
      "2024-01-07 16:11:38.568107  | actor_loss/Max                  nan\n",
      "2024-01-07 16:11:38.568775  | value_loss/Average              nan\n",
      "2024-01-07 16:11:38.569085  | value_loss/Std                  nan\n",
      "2024-01-07 16:11:38.569554  | value_loss/Median               nan\n",
      "2024-01-07 16:11:38.569961  | value_loss/Min                  nan\n",
      "2024-01-07 16:11:38.570270  | value_loss/Max                  nan\n",
      "2024-01-07 16:11:38.570796  | prior_entropy/Average           nan\n",
      "2024-01-07 16:11:38.571130  | prior_entropy/Std               nan\n",
      "2024-01-07 16:11:38.571642  | prior_entropy/Median            nan\n",
      "2024-01-07 16:11:38.571985  | prior_entropy/Min               nan\n",
      "2024-01-07 16:11:38.572409  | prior_entropy/Max               nan\n",
      "2024-01-07 16:11:38.572833  | post_entropy/Average            nan\n",
      "2024-01-07 16:11:38.573327  | post_entropy/Std                nan\n",
      "2024-01-07 16:11:38.573687  | post_entropy/Median             nan\n",
      "2024-01-07 16:11:38.574063  | post_entropy/Min                nan\n",
      "2024-01-07 16:11:38.574635  | post_entropy/Max                nan\n",
      "2024-01-07 16:11:38.575094  | divergence/Average              nan\n",
      "2024-01-07 16:11:38.575478  | divergence/Std                  nan\n",
      "2024-01-07 16:11:38.575774  | divergence/Median               nan\n",
      "2024-01-07 16:11:38.576067  | divergence/Min                  nan\n",
      "2024-01-07 16:11:38.576381  | divergence/Max                  nan\n",
      "2024-01-07 16:11:38.576671  | reward_loss/Average             nan\n",
      "2024-01-07 16:11:38.576974  | reward_loss/Std                 nan\n",
      "2024-01-07 16:11:38.577915  | reward_loss/Median              nan\n",
      "2024-01-07 16:11:38.578278  | reward_loss/Min                 nan\n",
      "2024-01-07 16:11:38.578678  | reward_loss/Max                 nan\n",
      "2024-01-07 16:11:38.579026  | image_loss/Average              nan\n",
      "2024-01-07 16:11:38.579533  | image_loss/Std                  nan\n",
      "2024-01-07 16:11:38.580031  | image_loss/Median               nan\n",
      "2024-01-07 16:11:38.580676  | image_loss/Min                  nan\n",
      "2024-01-07 16:11:38.581096  | image_loss/Max                  nan\n",
      "2024-01-07 16:11:38.581796  | pcont_loss/Average              nan\n",
      "2024-01-07 16:11:38.582290  | pcont_loss/Std                  nan\n",
      "2024-01-07 16:11:38.582658  | pcont_loss/Median               nan\n",
      "2024-01-07 16:11:38.583044  | pcont_loss/Min                  nan\n",
      "2024-01-07 16:11:38.583689  | pcont_loss/Max                  nan\n",
      "2024-01-07 16:11:38.584093  | -----------------------------  ----------\n",
      "2024-01-07 16:11:38.584898  | dreamer_assault_0 itr #2999 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n",
      "2024-01-07 16:11:42.224129  | dreamer_assault_0 itr #3999 saving snapshot...\n",
      "2024-01-07 16:11:42.282119  | dreamer_assault_0 itr #3999 saved\n",
      "2024-01-07 16:11:42.300619  | -----------------------------  ----------\n",
      "2024-01-07 16:11:42.302267  | Diagnostics/NewCompletedTrajs     4\n",
      "2024-01-07 16:11:42.303576  | Diagnostics/StepsInTrajWindow  3876\n",
      "2024-01-07 16:11:42.304595  | Diagnostics/Iteration          3999\n",
      "2024-01-07 16:11:42.305647  | Diagnostics/CumTime (s)          16.0342\n",
      "2024-01-07 16:11:42.307215  | Diagnostics/CumSteps           4000\n",
      "2024-01-07 16:11:42.308053  | Diagnostics/CumCompletedTrajs    14\n",
      "2024-01-07 16:11:42.308945  | Diagnostics/CumUpdates            0\n",
      "2024-01-07 16:11:42.310909  | Diagnostics/StepsPerSecond      266.656\n",
      "2024-01-07 16:11:42.312345  | Diagnostics/UpdatesPerSecond      0\n",
      "2024-01-07 16:11:42.313451  | Diagnostics/ReplayRatio           0\n",
      "2024-01-07 16:11:42.314424  | Diagnostics/CumReplayRatio        0\n",
      "2024-01-07 16:11:42.315904  | Length/Average                  276.857\n",
      "2024-01-07 16:11:42.316905  | Length/Std                       70.1456\n",
      "2024-01-07 16:11:42.318150  | Length/Median                   291\n",
      "2024-01-07 16:11:42.318977  | Length/Min                      123\n",
      "2024-01-07 16:11:42.319930  | Length/Max                      369\n",
      "2024-01-07 16:11:42.320889  | Return/Average                   70.5\n",
      "2024-01-07 16:11:42.321743  | Return/Std                       27.0416\n",
      "2024-01-07 16:11:42.322593  | Return/Median                    73.5\n",
      "2024-01-07 16:11:42.324572  | Return/Min                       21\n",
      "2024-01-07 16:11:42.325451  | Return/Max                      105\n",
      "2024-01-07 16:11:42.326601  | NonzeroRewards/Average            3.35714\n",
      "2024-01-07 16:11:42.327454  | NonzeroRewards/Std                1.2877\n",
      "2024-01-07 16:11:42.328801  | NonzeroRewards/Median             3.5\n",
      "2024-01-07 16:11:42.329669  | NonzeroRewards/Min                1\n",
      "2024-01-07 16:11:42.330926  | NonzeroRewards/Max                5\n",
      "2024-01-07 16:11:42.331747  | DiscountedReturn/Average         26.0376\n",
      "2024-01-07 16:11:42.332550  | DiscountedReturn/Std             11.7054\n",
      "2024-01-07 16:11:42.333616  | DiscountedReturn/Median          27.1048\n",
      "2024-01-07 16:11:42.334219  | DiscountedReturn/Min              7.84275\n",
      "2024-01-07 16:11:42.334818  | DiscountedReturn/Max             49.7507\n",
      "2024-01-07 16:11:42.335781  | GameScore/Average                70.5\n",
      "2024-01-07 16:11:42.336460  | GameScore/Std                    27.0416\n",
      "2024-01-07 16:11:42.337004  | GameScore/Median                 73.5\n",
      "2024-01-07 16:11:42.337474  | GameScore/Min                    21\n",
      "2024-01-07 16:11:42.338417  | GameScore/Max                   105\n",
      "2024-01-07 16:11:42.338995  | loss/Average                    nan\n",
      "2024-01-07 16:11:42.339836  | loss/Std                        nan\n",
      "2024-01-07 16:11:42.340357  | loss/Median                     nan\n",
      "2024-01-07 16:11:42.340799  | loss/Min                        nan\n",
      "2024-01-07 16:11:42.341423  | loss/Max                        nan\n",
      "2024-01-07 16:11:42.341972  | grad_norm_model/Average         nan\n",
      "2024-01-07 16:11:42.342491  | grad_norm_model/Std             nan\n",
      "2024-01-07 16:11:42.343224  | grad_norm_model/Median          nan\n",
      "2024-01-07 16:11:42.343861  | grad_norm_model/Min             nan\n",
      "2024-01-07 16:11:42.344225  | grad_norm_model/Max             nan\n",
      "2024-01-07 16:11:42.344602  | grad_norm_actor/Average         nan\n",
      "2024-01-07 16:11:42.345071  | grad_norm_actor/Std             nan\n",
      "2024-01-07 16:11:42.345703  | grad_norm_actor/Median          nan\n",
      "2024-01-07 16:11:42.346643  | grad_norm_actor/Min             nan\n",
      "2024-01-07 16:11:42.347135  | grad_norm_actor/Max             nan\n",
      "2024-01-07 16:11:42.347866  | grad_norm_value/Average         nan\n",
      "2024-01-07 16:11:42.348433  | grad_norm_value/Std             nan\n",
      "2024-01-07 16:11:42.348962  | grad_norm_value/Median          nan\n",
      "2024-01-07 16:11:42.349357  | grad_norm_value/Min             nan\n",
      "2024-01-07 16:11:42.349905  | grad_norm_value/Max             nan\n",
      "2024-01-07 16:11:42.350309  | model_loss/Average              nan\n",
      "2024-01-07 16:11:42.350890  | model_loss/Std                  nan\n",
      "2024-01-07 16:11:42.351253  | model_loss/Median               nan\n",
      "2024-01-07 16:11:42.351590  | model_loss/Min                  nan\n",
      "2024-01-07 16:11:42.351888  | model_loss/Max                  nan\n",
      "2024-01-07 16:11:42.352177  | actor_loss/Average              nan\n",
      "2024-01-07 16:11:42.352696  | actor_loss/Std                  nan\n",
      "2024-01-07 16:11:42.353089  | actor_loss/Median               nan\n",
      "2024-01-07 16:11:42.353360  | actor_loss/Min                  nan\n",
      "2024-01-07 16:11:42.353821  | actor_loss/Max                  nan\n",
      "2024-01-07 16:11:42.354205  | value_loss/Average              nan\n",
      "2024-01-07 16:11:42.354579  | value_loss/Std                  nan\n",
      "2024-01-07 16:11:42.354986  | value_loss/Median               nan\n",
      "2024-01-07 16:11:42.355400  | value_loss/Min                  nan\n",
      "2024-01-07 16:11:42.355837  | value_loss/Max                  nan\n",
      "2024-01-07 16:11:42.356364  | prior_entropy/Average           nan\n",
      "2024-01-07 16:11:42.356797  | prior_entropy/Std               nan\n",
      "2024-01-07 16:11:42.357329  | prior_entropy/Median            nan\n",
      "2024-01-07 16:11:42.357727  | prior_entropy/Min               nan\n",
      "2024-01-07 16:11:42.358131  | prior_entropy/Max               nan\n",
      "2024-01-07 16:11:42.358479  | post_entropy/Average            nan\n",
      "2024-01-07 16:11:42.358912  | post_entropy/Std                nan\n",
      "2024-01-07 16:11:42.359190  | post_entropy/Median             nan\n",
      "2024-01-07 16:11:42.359484  | post_entropy/Min                nan\n",
      "2024-01-07 16:11:42.359786  | post_entropy/Max                nan\n",
      "2024-01-07 16:11:42.360114  | divergence/Average              nan\n",
      "2024-01-07 16:11:42.360737  | divergence/Std                  nan\n",
      "2024-01-07 16:11:42.361069  | divergence/Median               nan\n",
      "2024-01-07 16:11:42.361385  | divergence/Min                  nan\n",
      "2024-01-07 16:11:42.361700  | divergence/Max                  nan\n",
      "2024-01-07 16:11:42.361997  | reward_loss/Average             nan\n",
      "2024-01-07 16:11:42.362282  | reward_loss/Std                 nan\n",
      "2024-01-07 16:11:42.362561  | reward_loss/Median              nan\n",
      "2024-01-07 16:11:42.362872  | reward_loss/Min                 nan\n",
      "2024-01-07 16:11:42.363214  | reward_loss/Max                 nan\n",
      "2024-01-07 16:11:42.364046  | image_loss/Average              nan\n",
      "2024-01-07 16:11:42.364312  | image_loss/Std                  nan\n",
      "2024-01-07 16:11:42.364720  | image_loss/Median               nan\n",
      "2024-01-07 16:11:42.365124  | image_loss/Min                  nan\n",
      "2024-01-07 16:11:42.365498  | image_loss/Max                  nan\n",
      "2024-01-07 16:11:42.365799  | pcont_loss/Average              nan\n",
      "2024-01-07 16:11:42.366204  | pcont_loss/Std                  nan\n",
      "2024-01-07 16:11:42.366541  | pcont_loss/Median               nan\n",
      "2024-01-07 16:11:42.366858  | pcont_loss/Min                  nan\n",
      "2024-01-07 16:11:42.367122  | pcont_loss/Max                  nan\n",
      "2024-01-07 16:11:42.367529  | -----------------------------  ----------\n",
      "2024-01-07 16:11:42.368032  | dreamer_assault_0 itr #3999 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n",
      "2024-01-07 16:11:46.177441  | dreamer_assault_0 itr #4999 saving snapshot...\n",
      "2024-01-07 16:11:46.220157  | dreamer_assault_0 itr #4999 saved\n",
      "2024-01-07 16:11:46.226618  | -----------------------------  ----------\n",
      "2024-01-07 16:11:46.227340  | Diagnostics/NewCompletedTrajs     3\n",
      "2024-01-07 16:11:46.227627  | Diagnostics/StepsInTrajWindow  4819\n",
      "2024-01-07 16:11:46.228022  | Diagnostics/Iteration          4999\n",
      "2024-01-07 16:11:46.228761  | Diagnostics/CumTime (s)          19.9709\n",
      "2024-01-07 16:11:46.229271  | Diagnostics/CumSteps           5000\n",
      "2024-01-07 16:11:46.229673  | Diagnostics/CumCompletedTrajs    17\n",
      "2024-01-07 16:11:46.229946  | Diagnostics/CumUpdates            0\n",
      "2024-01-07 16:11:46.230343  | Diagnostics/StepsPerSecond      254.022\n",
      "2024-01-07 16:11:46.230708  | Diagnostics/UpdatesPerSecond      0\n",
      "2024-01-07 16:11:46.231069  | Diagnostics/ReplayRatio           0\n",
      "2024-01-07 16:11:46.231445  | Diagnostics/CumReplayRatio        0\n",
      "2024-01-07 16:11:46.231881  | Length/Average                  283.471\n",
      "2024-01-07 16:11:46.232236  | Length/Std                       66.6352\n",
      "2024-01-07 16:11:46.232695  | Length/Median                   292\n",
      "2024-01-07 16:11:46.233304  | Length/Min                      123\n",
      "2024-01-07 16:11:46.233762  | Length/Max                      369\n",
      "2024-01-07 16:11:46.234530  | Return/Average                   77.8235\n",
      "2024-01-07 16:11:46.234950  | Return/Std                       29.4922\n",
      "2024-01-07 16:11:46.235365  | Return/Median                    84\n",
      "2024-01-07 16:11:46.235761  | Return/Min                       21\n",
      "2024-01-07 16:11:46.236191  | Return/Max                      126\n",
      "2024-01-07 16:11:46.236710  | NonzeroRewards/Average            3.70588\n",
      "2024-01-07 16:11:46.237175  | NonzeroRewards/Std                1.40439\n",
      "2024-01-07 16:11:46.237666  | NonzeroRewards/Median             4\n",
      "2024-01-07 16:11:46.238166  | NonzeroRewards/Min                1\n",
      "2024-01-07 16:11:46.238527  | NonzeroRewards/Max                6\n",
      "2024-01-07 16:11:46.238909  | DiscountedReturn/Average         29.3402\n",
      "2024-01-07 16:11:46.240578  | DiscountedReturn/Std             12.8212\n",
      "2024-01-07 16:11:46.241013  | DiscountedReturn/Median          31.6226\n",
      "2024-01-07 16:11:46.241444  | DiscountedReturn/Min              7.84275\n",
      "2024-01-07 16:11:46.241868  | DiscountedReturn/Max             49.7507\n",
      "2024-01-07 16:11:46.242260  | GameScore/Average                77.8235\n",
      "2024-01-07 16:11:46.243039  | GameScore/Std                    29.4922\n",
      "2024-01-07 16:11:46.243634  | GameScore/Median                 84\n",
      "2024-01-07 16:11:46.243934  | GameScore/Min                    21\n",
      "2024-01-07 16:11:46.244494  | GameScore/Max                   126\n",
      "2024-01-07 16:11:46.244980  | loss/Average                    nan\n",
      "2024-01-07 16:11:46.245488  | loss/Std                        nan\n",
      "2024-01-07 16:11:46.245877  | loss/Median                     nan\n",
      "2024-01-07 16:11:46.246163  | loss/Min                        nan\n",
      "2024-01-07 16:11:46.246611  | loss/Max                        nan\n",
      "2024-01-07 16:11:46.247074  | grad_norm_model/Average         nan\n",
      "2024-01-07 16:11:46.247437  | grad_norm_model/Std             nan\n",
      "2024-01-07 16:11:46.247728  | grad_norm_model/Median          nan\n",
      "2024-01-07 16:11:46.247986  | grad_norm_model/Min             nan\n",
      "2024-01-07 16:11:46.248245  | grad_norm_model/Max             nan\n",
      "2024-01-07 16:11:46.248500  | grad_norm_actor/Average         nan\n",
      "2024-01-07 16:11:46.248748  | grad_norm_actor/Std             nan\n",
      "2024-01-07 16:11:46.249004  | grad_norm_actor/Median          nan\n",
      "2024-01-07 16:11:46.249766  | grad_norm_actor/Min             nan\n",
      "2024-01-07 16:11:46.250111  | grad_norm_actor/Max             nan\n",
      "2024-01-07 16:11:46.250446  | grad_norm_value/Average         nan\n",
      "2024-01-07 16:11:46.250790  | grad_norm_value/Std             nan\n",
      "2024-01-07 16:11:46.251085  | grad_norm_value/Median          nan\n",
      "2024-01-07 16:11:46.251560  | grad_norm_value/Min             nan\n",
      "2024-01-07 16:11:46.251901  | grad_norm_value/Max             nan\n",
      "2024-01-07 16:11:46.252228  | model_loss/Average              nan\n",
      "2024-01-07 16:11:46.252730  | model_loss/Std                  nan\n",
      "2024-01-07 16:11:46.253122  | model_loss/Median               nan\n",
      "2024-01-07 16:11:46.253797  | model_loss/Min                  nan\n",
      "2024-01-07 16:11:46.254208  | model_loss/Max                  nan\n",
      "2024-01-07 16:11:46.254516  | actor_loss/Average              nan\n",
      "2024-01-07 16:11:46.254885  | actor_loss/Std                  nan\n",
      "2024-01-07 16:11:46.255362  | actor_loss/Median               nan\n",
      "2024-01-07 16:11:46.255716  | actor_loss/Min                  nan\n",
      "2024-01-07 16:11:46.256041  | actor_loss/Max                  nan\n",
      "2024-01-07 16:11:46.256831  | value_loss/Average              nan\n",
      "2024-01-07 16:11:46.257252  | value_loss/Std                  nan\n",
      "2024-01-07 16:11:46.257627  | value_loss/Median               nan\n",
      "2024-01-07 16:11:46.258063  | value_loss/Min                  nan\n",
      "2024-01-07 16:11:46.258487  | value_loss/Max                  nan\n",
      "2024-01-07 16:11:46.258897  | prior_entropy/Average           nan\n",
      "2024-01-07 16:11:46.259442  | prior_entropy/Std               nan\n",
      "2024-01-07 16:11:46.259921  | prior_entropy/Median            nan\n",
      "2024-01-07 16:11:46.260594  | prior_entropy/Min               nan\n",
      "2024-01-07 16:11:46.261015  | prior_entropy/Max               nan\n",
      "2024-01-07 16:11:46.261455  | post_entropy/Average            nan\n",
      "2024-01-07 16:11:46.262226  | post_entropy/Std                nan\n",
      "2024-01-07 16:11:46.262717  | post_entropy/Median             nan\n",
      "2024-01-07 16:11:46.263635  | post_entropy/Min                nan\n",
      "2024-01-07 16:11:46.264099  | post_entropy/Max                nan\n",
      "2024-01-07 16:11:46.264721  | divergence/Average              nan\n",
      "2024-01-07 16:11:46.265106  | divergence/Std                  nan\n",
      "2024-01-07 16:11:46.265498  | divergence/Median               nan\n",
      "2024-01-07 16:11:46.266244  | divergence/Min                  nan\n",
      "2024-01-07 16:11:46.266829  | divergence/Max                  nan\n",
      "2024-01-07 16:11:46.267336  | reward_loss/Average             nan\n",
      "2024-01-07 16:11:46.267737  | reward_loss/Std                 nan\n",
      "2024-01-07 16:11:46.268190  | reward_loss/Median              nan\n",
      "2024-01-07 16:11:46.268649  | reward_loss/Min                 nan\n",
      "2024-01-07 16:11:46.269100  | reward_loss/Max                 nan\n",
      "2024-01-07 16:11:46.269537  | image_loss/Average              nan\n",
      "2024-01-07 16:11:46.269941  | image_loss/Std                  nan\n",
      "2024-01-07 16:11:46.270327  | image_loss/Median               nan\n",
      "2024-01-07 16:11:46.270718  | image_loss/Min                  nan\n",
      "2024-01-07 16:11:46.271127  | image_loss/Max                  nan\n",
      "2024-01-07 16:11:46.272438  | pcont_loss/Average              nan\n",
      "2024-01-07 16:11:46.272891  | pcont_loss/Std                  nan\n",
      "2024-01-07 16:11:46.273533  | pcont_loss/Median               nan\n",
      "2024-01-07 16:11:46.274065  | pcont_loss/Min                  nan\n",
      "2024-01-07 16:11:46.274443  | pcont_loss/Max                  nan\n",
      "2024-01-07 16:11:46.274903  | -----------------------------  ----------\n",
      "2024-01-07 16:11:46.276041  | dreamer_assault_0 itr #4999 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imagination: 100%|██████████| 100/100 [01:57<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 16:13:47.608939  | dreamer_assault_0 itr #5999 saving snapshot...\n",
      "2024-01-07 16:13:47.718611  | dreamer_assault_0 itr #5999 saved\n",
      "2024-01-07 16:13:47.726787  | -----------------------------  ---------------\n",
      "2024-01-07 16:13:47.727238  | Diagnostics/NewCompletedTrajs      5\n",
      "2024-01-07 16:13:47.727628  | Diagnostics/StepsInTrajWindow   5995\n",
      "2024-01-07 16:13:47.728021  | Diagnostics/Iteration           5999\n",
      "2024-01-07 16:13:47.728429  | Diagnostics/CumTime (s)          141.469\n",
      "2024-01-07 16:13:47.728849  | Diagnostics/CumSteps            6000\n",
      "2024-01-07 16:13:47.729703  | Diagnostics/CumCompletedTrajs     22\n",
      "2024-01-07 16:13:47.730186  | Diagnostics/CumUpdates             0\n",
      "2024-01-07 16:13:47.730601  | Diagnostics/StepsPerSecond         8.23055\n",
      "2024-01-07 16:13:47.731053  | Diagnostics/UpdatesPerSecond       0\n",
      "2024-01-07 16:13:47.731473  | Diagnostics/ReplayRatio            0\n",
      "2024-01-07 16:13:47.731955  | Diagnostics/CumReplayRatio         0\n",
      "2024-01-07 16:13:47.732813  | Length/Average                   272.5\n",
      "2024-01-07 16:13:47.733239  | Length/Std                        70.1088\n",
      "2024-01-07 16:13:47.733742  | Length/Median                    291.5\n",
      "2024-01-07 16:13:47.734359  | Length/Min                       123\n",
      "2024-01-07 16:13:47.734902  | Length/Max                       369\n",
      "2024-01-07 16:13:47.735326  | Return/Average                    75.4091\n",
      "2024-01-07 16:13:47.735748  | Return/Std                        32.6923\n",
      "2024-01-07 16:13:47.736222  | Return/Median                     73.5\n",
      "2024-01-07 16:13:47.736612  | Return/Min                        21\n",
      "2024-01-07 16:13:47.736991  | Return/Max                       147\n",
      "2024-01-07 16:13:47.737463  | NonzeroRewards/Average             3.59091\n",
      "2024-01-07 16:13:47.737941  | NonzeroRewards/Std                 1.55678\n",
      "2024-01-07 16:13:47.738196  | NonzeroRewards/Median              3.5\n",
      "2024-01-07 16:13:47.738486  | NonzeroRewards/Min                 1\n",
      "2024-01-07 16:13:47.739113  | NonzeroRewards/Max                 7\n",
      "2024-01-07 16:13:47.739457  | DiscountedReturn/Average          29.2612\n",
      "2024-01-07 16:13:47.739858  | DiscountedReturn/Std              12.098\n",
      "2024-01-07 16:13:47.740268  | DiscountedReturn/Median           27.7114\n",
      "2024-01-07 16:13:47.740834  | DiscountedReturn/Min               7.84275\n",
      "2024-01-07 16:13:47.741107  | DiscountedReturn/Max              49.7507\n",
      "2024-01-07 16:13:47.741521  | GameScore/Average                 75.4091\n",
      "2024-01-07 16:13:47.741855  | GameScore/Std                     32.6923\n",
      "2024-01-07 16:13:47.742100  | GameScore/Median                  73.5\n",
      "2024-01-07 16:13:47.742360  | GameScore/Min                     21\n",
      "2024-01-07 16:13:47.742633  | GameScore/Max                    147\n",
      "2024-01-07 16:13:47.742917  | loss/Average                   11508.3\n",
      "2024-01-07 16:13:47.743227  | loss/Std                         293.657\n",
      "2024-01-07 16:13:47.743614  | loss/Median                    11383.7\n",
      "2024-01-07 16:13:47.744009  | loss/Min                       11329.3\n",
      "2024-01-07 16:13:47.744539  | loss/Max                       12648.8\n",
      "2024-01-07 16:13:47.746147  | grad_norm_model/Average         1317.09\n",
      "2024-01-07 16:13:47.746568  | grad_norm_model/Std             1040.36\n",
      "2024-01-07 16:13:47.747294  | grad_norm_model/Median          1047.31\n",
      "2024-01-07 16:13:47.748248  | grad_norm_model/Min               98.6101\n",
      "2024-01-07 16:13:47.748762  | grad_norm_model/Max             5424.64\n",
      "2024-01-07 16:13:47.749533  | grad_norm_actor/Average            0.134114\n",
      "2024-01-07 16:13:47.750699  | grad_norm_actor/Std                0.120893\n",
      "2024-01-07 16:13:47.751206  | grad_norm_actor/Median             0.100736\n",
      "2024-01-07 16:13:47.752441  | grad_norm_actor/Min                0.000371994\n",
      "2024-01-07 16:13:47.752763  | grad_norm_actor/Max                0.400875\n",
      "2024-01-07 16:13:47.753204  | grad_norm_value/Average            6.04411\n",
      "2024-01-07 16:13:47.753632  | grad_norm_value/Std                5.20362\n",
      "2024-01-07 16:13:47.754027  | grad_norm_value/Median             3.95406\n",
      "2024-01-07 16:13:47.755045  | grad_norm_value/Min                0.00736419\n",
      "2024-01-07 16:13:47.755540  | grad_norm_value/Max               19.9156\n",
      "2024-01-07 16:13:47.755930  | model_loss/Average             11509.3\n",
      "2024-01-07 16:13:47.756439  | model_loss/Std                   293.02\n",
      "2024-01-07 16:13:47.756899  | model_loss/Median              11383.9\n",
      "2024-01-07 16:13:47.757369  | model_loss/Min                 11333.6\n",
      "2024-01-07 16:13:47.758535  | model_loss/Max                 12648.6\n",
      "2024-01-07 16:13:47.759029  | actor_loss/Average                -2.78645\n",
      "2024-01-07 16:13:47.759474  | actor_loss/Std                     2.01929\n",
      "2024-01-07 16:13:47.760281  | actor_loss/Median                 -2.28734\n",
      "2024-01-07 16:13:47.761017  | actor_loss/Min                    -7.64179\n",
      "2024-01-07 16:13:47.761767  | actor_loss/Max                     0.0039739\n",
      "2024-01-07 16:13:47.762239  | value_loss/Average                 1.78989\n",
      "2024-01-07 16:13:47.762728  | value_loss/Std                     0.734763\n",
      "2024-01-07 16:13:47.763196  | value_loss/Median                  1.80858\n",
      "2024-01-07 16:13:47.763631  | value_loss/Min                     0.196405\n",
      "2024-01-07 16:13:47.764111  | value_loss/Max                     3.45871\n",
      "2024-01-07 16:13:47.764600  | prior_entropy/Average             27.0327\n",
      "2024-01-07 16:13:47.764991  | prior_entropy/Std                  8.4201\n",
      "2024-01-07 16:13:47.766310  | prior_entropy/Median              23.1502\n",
      "2024-01-07 16:13:47.766774  | prior_entropy/Min                 15.2856\n",
      "2024-01-07 16:13:47.767312  | prior_entropy/Max                 38.3867\n",
      "2024-01-07 16:13:47.767806  | post_entropy/Average              21.3433\n",
      "2024-01-07 16:13:47.768189  | post_entropy/Std                  10.1552\n",
      "2024-01-07 16:13:47.768859  | post_entropy/Median               15.4538\n",
      "2024-01-07 16:13:47.769276  | post_entropy/Min                   9.66954\n",
      "2024-01-07 16:13:47.769694  | post_entropy/Max                  37.3938\n",
      "2024-01-07 16:13:47.770114  | divergence/Average                 5.74383\n",
      "2024-01-07 16:13:47.770953  | divergence/Std                     2.0572\n",
      "2024-01-07 16:13:47.771390  | divergence/Median                  5.57033\n",
      "2024-01-07 16:13:47.772049  | divergence/Min                     3\n",
      "2024-01-07 16:13:47.772744  | divergence/Max                    13.3545\n",
      "2024-01-07 16:13:47.773680  | reward_loss/Average                3.82368\n",
      "2024-01-07 16:13:47.774106  | reward_loss/Std                    0.414966\n",
      "2024-01-07 16:13:47.774733  | reward_loss/Median                 3.79668\n",
      "2024-01-07 16:13:47.775259  | reward_loss/Min                    2.68011\n",
      "2024-01-07 16:13:47.775828  | reward_loss/Max                    4.99279\n",
      "2024-01-07 16:13:47.776369  | image_loss/Average             11504.2\n",
      "2024-01-07 16:13:47.776788  | image_loss/Std                   291.866\n",
      "2024-01-07 16:13:47.777175  | image_loss/Median              11379.4\n",
      "2024-01-07 16:13:47.777655  | image_loss/Min                 11328.7\n",
      "2024-01-07 16:13:47.778079  | image_loss/Max                 12637.5\n",
      "2024-01-07 16:13:47.778374  | pcont_loss/Average                 0.0660159\n",
      "2024-01-07 16:13:47.778701  | pcont_loss/Std                     0.135899\n",
      "2024-01-07 16:13:47.779002  | pcont_loss/Median                  0.0262375\n",
      "2024-01-07 16:13:47.779293  | pcont_loss/Min                     0.0120549\n",
      "2024-01-07 16:13:47.779570  | pcont_loss/Max                     0.733148\n",
      "2024-01-07 16:13:47.780243  | -----------------------------  ---------------\n",
      "2024-01-07 16:13:47.780649  | dreamer_assault_0 itr #5999 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imagination: 100%|██████████| 100/100 [02:03<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 16:15:55.970858  | dreamer_assault_0 itr #6999 saving snapshot...\n",
      "2024-01-07 16:15:56.165458  | dreamer_assault_0 itr #6999 saved\n",
      "2024-01-07 16:15:56.189491  | -----------------------------  --------------\n",
      "2024-01-07 16:15:56.191275  | Diagnostics/NewCompletedTrajs      4\n",
      "2024-01-07 16:15:56.192486  | Diagnostics/StepsInTrajWindow   6999\n",
      "2024-01-07 16:15:56.194509  | Diagnostics/Iteration           6999\n",
      "2024-01-07 16:15:56.195827  | Diagnostics/CumTime (s)          269.917\n",
      "2024-01-07 16:15:56.197700  | Diagnostics/CumSteps            7000\n",
      "2024-01-07 16:15:56.198831  | Diagnostics/CumCompletedTrajs     26\n",
      "2024-01-07 16:15:56.199776  | Diagnostics/CumUpdates             0\n",
      "2024-01-07 16:15:56.201010  | Diagnostics/StepsPerSecond         7.78526\n",
      "2024-01-07 16:15:56.201936  | Diagnostics/UpdatesPerSecond       0\n",
      "2024-01-07 16:15:56.202735  | Diagnostics/ReplayRatio            0\n",
      "2024-01-07 16:15:56.203639  | Diagnostics/CumReplayRatio         0\n",
      "2024-01-07 16:15:56.206138  | Length/Average                   269.192\n",
      "2024-01-07 16:15:56.207772  | Length/Std                        71.861\n",
      "2024-01-07 16:15:56.209049  | Length/Median                    291.5\n",
      "2024-01-07 16:15:56.210362  | Length/Min                       120\n",
      "2024-01-07 16:15:56.211514  | Length/Max                       369\n",
      "2024-01-07 16:15:56.212454  | Return/Average                    67.8462\n",
      "2024-01-07 16:15:56.213400  | Return/Std                        36.5163\n",
      "2024-01-07 16:15:56.214184  | Return/Median                     63\n",
      "2024-01-07 16:15:56.215854  | Return/Min                         0\n",
      "2024-01-07 16:15:56.216516  | Return/Max                       147\n",
      "2024-01-07 16:15:56.217417  | NonzeroRewards/Average             3.23077\n",
      "2024-01-07 16:15:56.218321  | NonzeroRewards/Std                 1.73887\n",
      "2024-01-07 16:15:56.219947  | NonzeroRewards/Median              3\n",
      "2024-01-07 16:15:56.220722  | NonzeroRewards/Min                 0\n",
      "2024-01-07 16:15:56.221780  | NonzeroRewards/Max                 7\n",
      "2024-01-07 16:15:56.222423  | DiscountedReturn/Average          25.9104\n",
      "2024-01-07 16:15:56.223348  | DiscountedReturn/Std              14.1609\n",
      "2024-01-07 16:15:56.224115  | DiscountedReturn/Median           25.1884\n",
      "2024-01-07 16:15:56.224927  | DiscountedReturn/Min               0\n",
      "2024-01-07 16:15:56.225868  | DiscountedReturn/Max              49.7507\n",
      "2024-01-07 16:15:56.226716  | GameScore/Average                 67.8462\n",
      "2024-01-07 16:15:56.227293  | GameScore/Std                     36.5163\n",
      "2024-01-07 16:15:56.227862  | GameScore/Median                  63\n",
      "2024-01-07 16:15:56.228890  | GameScore/Min                      0\n",
      "2024-01-07 16:15:56.229472  | GameScore/Max                    147\n",
      "2024-01-07 16:15:56.230344  | loss/Average                   11324.3\n",
      "2024-01-07 16:15:56.231099  | loss/Std                          22.6375\n",
      "2024-01-07 16:15:56.231831  | loss/Median                    11322.3\n",
      "2024-01-07 16:15:56.232539  | loss/Min                       11288\n",
      "2024-01-07 16:15:56.233385  | loss/Max                       11407.6\n",
      "2024-01-07 16:15:56.233925  | grad_norm_model/Average          721.73\n",
      "2024-01-07 16:15:56.234404  | grad_norm_model/Std              540.351\n",
      "2024-01-07 16:15:56.234866  | grad_norm_model/Median           617.904\n",
      "2024-01-07 16:15:56.235328  | grad_norm_model/Min               28.637\n",
      "2024-01-07 16:15:56.235786  | grad_norm_model/Max             2899.28\n",
      "2024-01-07 16:15:56.236250  | grad_norm_actor/Average            0.0703601\n",
      "2024-01-07 16:15:56.236674  | grad_norm_actor/Std                0.046567\n",
      "2024-01-07 16:15:56.237090  | grad_norm_actor/Median             0.0526776\n",
      "2024-01-07 16:15:56.237512  | grad_norm_actor/Min                0.0158057\n",
      "2024-01-07 16:15:56.238921  | grad_norm_actor/Max                0.190252\n",
      "2024-01-07 16:15:56.239339  | grad_norm_value/Average           39.2179\n",
      "2024-01-07 16:15:56.239739  | grad_norm_value/Std               21.0546\n",
      "2024-01-07 16:15:56.240140  | grad_norm_value/Median            36.2172\n",
      "2024-01-07 16:15:56.240545  | grad_norm_value/Min                7.00692\n",
      "2024-01-07 16:15:56.240971  | grad_norm_value/Max               96.6864\n",
      "2024-01-07 16:15:56.242110  | model_loss/Average             11340.3\n",
      "2024-01-07 16:15:56.242532  | model_loss/Std                    17.6871\n",
      "2024-01-07 16:15:56.242940  | model_loss/Median              11335\n",
      "2024-01-07 16:15:56.243405  | model_loss/Min                 11318.9\n",
      "2024-01-07 16:15:56.243842  | model_loss/Max                 11414.7\n",
      "2024-01-07 16:15:56.244235  | actor_loss/Average               -19.4092\n",
      "2024-01-07 16:15:56.244631  | actor_loss/Std                     8.81042\n",
      "2024-01-07 16:15:56.245200  | actor_loss/Median                -17.5166\n",
      "2024-01-07 16:15:56.246391  | actor_loss/Min                   -37.3229\n",
      "2024-01-07 16:15:56.246936  | actor_loss/Max                    -7.81178\n",
      "2024-01-07 16:15:56.247498  | value_loss/Average                 3.43251\n",
      "2024-01-07 16:15:56.247893  | value_loss/Std                     0.888931\n",
      "2024-01-07 16:15:56.248451  | value_loss/Median                  3.22379\n",
      "2024-01-07 16:15:56.248896  | value_loss/Min                     2.17402\n",
      "2024-01-07 16:15:56.249465  | value_loss/Max                     5.36494\n",
      "2024-01-07 16:15:56.249904  | prior_entropy/Average             15.3231\n",
      "2024-01-07 16:15:56.250565  | prior_entropy/Std                  2.10377\n",
      "2024-01-07 16:15:56.250968  | prior_entropy/Median              15.0052\n",
      "2024-01-07 16:15:56.251361  | prior_entropy/Min                 11.5839\n",
      "2024-01-07 16:15:56.251795  | prior_entropy/Max                 20.2719\n",
      "2024-01-07 16:15:56.252648  | post_entropy/Average               9.55907\n",
      "2024-01-07 16:15:56.253295  | post_entropy/Std                   1.767\n",
      "2024-01-07 16:15:56.253773  | post_entropy/Median                8.96813\n",
      "2024-01-07 16:15:56.254416  | post_entropy/Min                   7.01491\n",
      "2024-01-07 16:15:56.254939  | post_entropy/Max                  13.6224\n",
      "2024-01-07 16:15:56.255340  | divergence/Average                 4.98237\n",
      "2024-01-07 16:15:56.255909  | divergence/Std                     1.02017\n",
      "2024-01-07 16:15:56.256421  | divergence/Median                  4.95675\n",
      "2024-01-07 16:15:56.256816  | divergence/Min                     3\n",
      "2024-01-07 16:15:56.257207  | divergence/Max                     8.06998\n",
      "2024-01-07 16:15:56.257630  | reward_loss/Average                3.75412\n",
      "2024-01-07 16:15:56.258608  | reward_loss/Std                    0.374849\n",
      "2024-01-07 16:15:56.259045  | reward_loss/Median                 3.70394\n",
      "2024-01-07 16:15:56.259473  | reward_loss/Min                    2.85295\n",
      "2024-01-07 16:15:56.259888  | reward_loss/Max                    4.88826\n",
      "2024-01-07 16:15:56.260327  | image_loss/Average             11335.8\n",
      "2024-01-07 16:15:56.261331  | image_loss/Std                    17.6202\n",
      "2024-01-07 16:15:56.261787  | image_loss/Median              11330.3\n",
      "2024-01-07 16:15:56.263125  | image_loss/Min                 11314.4\n",
      "2024-01-07 16:15:56.263714  | image_loss/Max                 11410.3\n",
      "2024-01-07 16:15:56.264258  | pcont_loss/Average                 0.0229215\n",
      "2024-01-07 16:15:56.264782  | pcont_loss/Std                     0.00562001\n",
      "2024-01-07 16:15:56.265349  | pcont_loss/Median                  0.0224308\n",
      "2024-01-07 16:15:56.266362  | pcont_loss/Min                     0.00978457\n",
      "2024-01-07 16:15:56.266842  | pcont_loss/Max                     0.0385855\n",
      "2024-01-07 16:15:56.267442  | -----------------------------  --------------\n",
      "2024-01-07 16:15:56.268338  | dreamer_assault_0 itr #6999 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imagination: 100%|██████████| 100/100 [02:03<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 16:18:03.855901  | dreamer_assault_0 itr #7999 saving snapshot...\n",
      "2024-01-07 16:18:04.028521  | dreamer_assault_0 itr #7999 saved\n",
      "2024-01-07 16:18:04.054324  | -----------------------------  --------------\n",
      "2024-01-07 16:18:04.056083  | Diagnostics/NewCompletedTrajs      3\n",
      "2024-01-07 16:18:04.057111  | Diagnostics/StepsInTrajWindow   7774\n",
      "2024-01-07 16:18:04.058261  | Diagnostics/Iteration           7999\n",
      "2024-01-07 16:18:04.059300  | Diagnostics/CumTime (s)          397.78\n",
      "2024-01-07 16:18:04.060222  | Diagnostics/CumSteps            8000\n",
      "2024-01-07 16:18:04.063117  | Diagnostics/CumCompletedTrajs     29\n",
      "2024-01-07 16:18:04.064536  | Diagnostics/CumUpdates             0\n",
      "2024-01-07 16:18:04.065592  | Diagnostics/StepsPerSecond         7.82086\n",
      "2024-01-07 16:18:04.066762  | Diagnostics/UpdatesPerSecond       0\n",
      "2024-01-07 16:18:04.067732  | Diagnostics/ReplayRatio            0\n",
      "2024-01-07 16:18:04.068859  | Diagnostics/CumReplayRatio         0\n",
      "2024-01-07 16:18:04.070073  | Length/Average                   268.069\n",
      "2024-01-07 16:18:04.072980  | Length/Std                        68.1256\n",
      "2024-01-07 16:18:04.074271  | Length/Median                    290\n",
      "2024-01-07 16:18:04.076400  | Length/Min                       120\n",
      "2024-01-07 16:18:04.077656  | Length/Max                       369\n",
      "2024-01-07 16:18:04.078854  | Return/Average                    66.6207\n",
      "2024-01-07 16:18:04.080017  | Return/Std                        34.9092\n",
      "2024-01-07 16:18:04.080896  | Return/Median                     63\n",
      "2024-01-07 16:18:04.081790  | Return/Min                         0\n",
      "2024-01-07 16:18:04.082605  | Return/Max                       147\n",
      "2024-01-07 16:18:04.083360  | NonzeroRewards/Average             3.17241\n",
      "2024-01-07 16:18:04.085108  | NonzeroRewards/Std                 1.66234\n",
      "2024-01-07 16:18:04.086324  | NonzeroRewards/Median              3\n",
      "2024-01-07 16:18:04.087276  | NonzeroRewards/Min                 0\n",
      "2024-01-07 16:18:04.088178  | NonzeroRewards/Max                 7\n",
      "2024-01-07 16:18:04.088812  | DiscountedReturn/Average          25.306\n",
      "2024-01-07 16:18:04.089485  | DiscountedReturn/Std              13.701\n",
      "2024-01-07 16:18:04.090720  | DiscountedReturn/Median           25.1782\n",
      "2024-01-07 16:18:04.091582  | DiscountedReturn/Min               0\n",
      "2024-01-07 16:18:04.092016  | DiscountedReturn/Max              49.7507\n",
      "2024-01-07 16:18:04.092438  | GameScore/Average                 66.6207\n",
      "2024-01-07 16:18:04.092788  | GameScore/Std                     34.9092\n",
      "2024-01-07 16:18:04.093664  | GameScore/Median                  63\n",
      "2024-01-07 16:18:04.094190  | GameScore/Min                      0\n",
      "2024-01-07 16:18:04.094563  | GameScore/Max                    147\n",
      "2024-01-07 16:18:04.094934  | loss/Average                   11264.8\n",
      "2024-01-07 16:18:04.095354  | loss/Std                          13.7801\n",
      "2024-01-07 16:18:04.096575  | loss/Median                    11259.4\n",
      "2024-01-07 16:18:04.097140  | loss/Min                       11246.3\n",
      "2024-01-07 16:18:04.097664  | loss/Max                       11310.4\n",
      "2024-01-07 16:18:04.098090  | grad_norm_model/Average          343.708\n",
      "2024-01-07 16:18:04.098512  | grad_norm_model/Std              224.131\n",
      "2024-01-07 16:18:04.099326  | grad_norm_model/Median           293.214\n",
      "2024-01-07 16:18:04.099700  | grad_norm_model/Min               26.9797\n",
      "2024-01-07 16:18:04.100125  | grad_norm_model/Max              968.31\n",
      "2024-01-07 16:18:04.102100  | grad_norm_actor/Average            0.0137806\n",
      "2024-01-07 16:18:04.102854  | grad_norm_actor/Std                0.00443288\n",
      "2024-01-07 16:18:04.103443  | grad_norm_actor/Median             0.0121728\n",
      "2024-01-07 16:18:04.104010  | grad_norm_actor/Min                0.00857148\n",
      "2024-01-07 16:18:04.104565  | grad_norm_actor/Max                0.0251743\n",
      "2024-01-07 16:18:04.105130  | grad_norm_value/Average           78.8772\n",
      "2024-01-07 16:18:04.105566  | grad_norm_value/Std               37.0928\n",
      "2024-01-07 16:18:04.106257  | grad_norm_value/Median            77.0772\n",
      "2024-01-07 16:18:04.106730  | grad_norm_value/Min               11.62\n",
      "2024-01-07 16:18:04.107278  | grad_norm_value/Max              175.41\n",
      "2024-01-07 16:18:04.107855  | model_loss/Average             11326.3\n",
      "2024-01-07 16:18:04.108455  | model_loss/Std                     5.021\n",
      "2024-01-07 16:18:04.109059  | model_loss/Median              11325.6\n",
      "2024-01-07 16:18:04.110220  | model_loss/Min                 11316.5\n",
      "2024-01-07 16:18:04.110962  | model_loss/Max                 11345.2\n",
      "2024-01-07 16:18:04.111587  | actor_loss/Average               -70.5959\n",
      "2024-01-07 16:18:04.112124  | actor_loss/Std                    15.4\n",
      "2024-01-07 16:18:04.112506  | actor_loss/Median                -77.3582\n",
      "2024-01-07 16:18:04.113034  | actor_loss/Min                   -86.7035\n",
      "2024-01-07 16:18:04.113555  | actor_loss/Max                   -39.2069\n",
      "2024-01-07 16:18:04.114052  | value_loss/Average                 9.07678\n",
      "2024-01-07 16:18:04.114577  | value_loss/Std                     2.72564\n",
      "2024-01-07 16:18:04.115120  | value_loss/Median                  9.24554\n",
      "2024-01-07 16:18:04.115667  | value_loss/Min                     4.44828\n",
      "2024-01-07 16:18:04.116212  | value_loss/Max                    15.2067\n",
      "2024-01-07 16:18:04.116741  | prior_entropy/Average              8.75125\n",
      "2024-01-07 16:18:04.117254  | prior_entropy/Std                  1.37252\n",
      "2024-01-07 16:18:04.117807  | prior_entropy/Median               8.38481\n",
      "2024-01-07 16:18:04.118264  | prior_entropy/Min                  6.47519\n",
      "2024-01-07 16:18:04.118762  | prior_entropy/Max                 11.9493\n",
      "2024-01-07 16:18:04.119241  | post_entropy/Average               4.55233\n",
      "2024-01-07 16:18:04.119737  | post_entropy/Std                   1.20141\n",
      "2024-01-07 16:18:04.120156  | post_entropy/Median                4.18878\n",
      "2024-01-07 16:18:04.120576  | post_entropy/Min                   2.53325\n",
      "2024-01-07 16:18:04.120967  | post_entropy/Max                   7.42225\n",
      "2024-01-07 16:18:04.121359  | divergence/Average                 3.91959\n",
      "2024-01-07 16:18:04.121764  | divergence/Std                     0.933784\n",
      "2024-01-07 16:18:04.122174  | divergence/Median                  3.60338\n",
      "2024-01-07 16:18:04.122578  | divergence/Min                     3\n",
      "2024-01-07 16:18:04.123010  | divergence/Max                     7.34248\n",
      "2024-01-07 16:18:04.123442  | reward_loss/Average                3.44445\n",
      "2024-01-07 16:18:04.123826  | reward_loss/Std                    0.440419\n",
      "2024-01-07 16:18:04.124294  | reward_loss/Median                 3.36341\n",
      "2024-01-07 16:18:04.124805  | reward_loss/Min                    2.58774\n",
      "2024-01-07 16:18:04.126451  | reward_loss/Max                    4.64768\n",
      "2024-01-07 16:18:04.126977  | image_loss/Average             11322.2\n",
      "2024-01-07 16:18:04.127388  | image_loss/Std                     5.01871\n",
      "2024-01-07 16:18:04.127919  | image_loss/Median              11321.8\n",
      "2024-01-07 16:18:04.128450  | image_loss/Min                 11312.9\n",
      "2024-01-07 16:18:04.128997  | image_loss/Max                 11341.4\n",
      "2024-01-07 16:18:04.129482  | pcont_loss/Average                 0.0234618\n",
      "2024-01-07 16:18:04.129843  | pcont_loss/Std                     0.00618432\n",
      "2024-01-07 16:18:04.130286  | pcont_loss/Median                  0.0232523\n",
      "2024-01-07 16:18:04.130769  | pcont_loss/Min                     0.00916437\n",
      "2024-01-07 16:18:04.134335  | pcont_loss/Max                     0.0423078\n",
      "2024-01-07 16:18:04.134770  | -----------------------------  --------------\n",
      "2024-01-07 16:18:04.135565  | dreamer_assault_0 itr #7999 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imagination: 100%|██████████| 100/100 [02:06<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 16:20:14.832356  | dreamer_assault_0 itr #8999 saving snapshot...\n",
      "2024-01-07 16:20:14.952993  | dreamer_assault_0 itr #8999 saved\n",
      "2024-01-07 16:20:14.961429  | -----------------------------  --------------\n",
      "2024-01-07 16:20:14.962074  | Diagnostics/NewCompletedTrajs      5\n",
      "2024-01-07 16:20:14.962560  | Diagnostics/StepsInTrajWindow   8990\n",
      "2024-01-07 16:20:14.962936  | Diagnostics/Iteration           8999\n",
      "2024-01-07 16:20:14.963326  | Diagnostics/CumTime (s)          528.704\n",
      "2024-01-07 16:20:14.963829  | Diagnostics/CumSteps            9000\n",
      "2024-01-07 16:20:14.964666  | Diagnostics/CumCompletedTrajs     34\n",
      "2024-01-07 16:20:14.965194  | Diagnostics/CumUpdates             0\n",
      "2024-01-07 16:20:14.965843  | Diagnostics/StepsPerSecond         7.63804\n",
      "2024-01-07 16:20:14.966425  | Diagnostics/UpdatesPerSecond       0\n",
      "2024-01-07 16:20:14.966827  | Diagnostics/ReplayRatio            0\n",
      "2024-01-07 16:20:14.967443  | Diagnostics/CumReplayRatio         0\n",
      "2024-01-07 16:20:14.967896  | Length/Average                   264.412\n",
      "2024-01-07 16:20:14.968637  | Length/Std                        67.6644\n",
      "2024-01-07 16:20:14.969034  | Length/Median                    269\n",
      "2024-01-07 16:20:14.969424  | Length/Min                       120\n",
      "2024-01-07 16:20:14.969895  | Length/Max                       369\n",
      "2024-01-07 16:20:14.971025  | Return/Average                    64.8529\n",
      "2024-01-07 16:20:14.971511  | Return/Std                        33.9256\n",
      "2024-01-07 16:20:14.972157  | Return/Median                     63\n",
      "2024-01-07 16:20:14.972579  | Return/Min                         0\n",
      "2024-01-07 16:20:14.973127  | Return/Max                       147\n",
      "2024-01-07 16:20:14.973568  | NonzeroRewards/Average             3.08824\n",
      "2024-01-07 16:20:14.974319  | NonzeroRewards/Std                 1.61551\n",
      "2024-01-07 16:20:14.974731  | NonzeroRewards/Median              3\n",
      "2024-01-07 16:20:14.975424  | NonzeroRewards/Min                 0\n",
      "2024-01-07 16:20:14.975935  | NonzeroRewards/Max                 7\n",
      "2024-01-07 16:20:14.976559  | DiscountedReturn/Average          24.7506\n",
      "2024-01-07 16:20:14.977081  | DiscountedReturn/Std              13.4774\n",
      "2024-01-07 16:20:14.977686  | DiscountedReturn/Median           24.6275\n",
      "2024-01-07 16:20:14.978100  | DiscountedReturn/Min               0\n",
      "2024-01-07 16:20:14.978699  | DiscountedReturn/Max              49.7507\n",
      "2024-01-07 16:20:14.979215  | GameScore/Average                 64.8529\n",
      "2024-01-07 16:20:14.979944  | GameScore/Std                     33.9256\n",
      "2024-01-07 16:20:14.980360  | GameScore/Median                  63\n",
      "2024-01-07 16:20:14.980663  | GameScore/Min                      0\n",
      "2024-01-07 16:20:14.980944  | GameScore/Max                    147\n",
      "2024-01-07 16:20:14.981899  | loss/Average                   11272.8\n",
      "2024-01-07 16:20:14.982304  | loss/Std                           5.93584\n",
      "2024-01-07 16:20:14.982643  | loss/Median                    11272.2\n",
      "2024-01-07 16:20:14.982990  | loss/Min                       11262.7\n",
      "2024-01-07 16:20:14.983349  | loss/Max                       11291.7\n",
      "2024-01-07 16:20:14.984141  | grad_norm_model/Average          331.15\n",
      "2024-01-07 16:20:14.984662  | grad_norm_model/Std              202.24\n",
      "2024-01-07 16:20:14.985032  | grad_norm_model/Median           293.191\n",
      "2024-01-07 16:20:14.985627  | grad_norm_model/Min               24.7805\n",
      "2024-01-07 16:20:14.986016  | grad_norm_model/Max             1084.8\n",
      "2024-01-07 16:20:14.986728  | grad_norm_actor/Average            0.0149357\n",
      "2024-01-07 16:20:14.987209  | grad_norm_actor/Std                0.0104041\n",
      "2024-01-07 16:20:14.987606  | grad_norm_actor/Median             0.0098172\n",
      "2024-01-07 16:20:14.988178  | grad_norm_actor/Min                0.00479533\n",
      "2024-01-07 16:20:14.988648  | grad_norm_actor/Max                0.03889\n",
      "2024-01-07 16:20:14.989021  | grad_norm_value/Average           37.8636\n",
      "2024-01-07 16:20:14.989532  | grad_norm_value/Std               31.8527\n",
      "2024-01-07 16:20:14.990037  | grad_norm_value/Median            32.024\n",
      "2024-01-07 16:20:14.990493  | grad_norm_value/Min                4.34437\n",
      "2024-01-07 16:20:14.990941  | grad_norm_value/Max              137.291\n",
      "2024-01-07 16:20:14.991425  | model_loss/Average             11324.6\n",
      "2024-01-07 16:20:14.991737  | model_loss/Std                     5.2157\n",
      "2024-01-07 16:20:14.992065  | model_loss/Median              11323.9\n",
      "2024-01-07 16:20:14.992451  | model_loss/Min                 11314.1\n",
      "2024-01-07 16:20:14.993332  | model_loss/Max                 11345.4\n",
      "2024-01-07 16:20:14.993723  | actor_loss/Average               -61.3034\n",
      "2024-01-07 16:20:14.994524  | actor_loss/Std                     5.32413\n",
      "2024-01-07 16:20:14.995225  | actor_loss/Median                -59.3639\n",
      "2024-01-07 16:20:14.995710  | actor_loss/Min                   -76.8385\n",
      "2024-01-07 16:20:14.996197  | actor_loss/Max                   -55.0369\n",
      "2024-01-07 16:20:14.997119  | value_loss/Average                 9.47825\n",
      "2024-01-07 16:20:14.997685  | value_loss/Std                     5.11388\n",
      "2024-01-07 16:20:14.998257  | value_loss/Median                  7.57145\n",
      "2024-01-07 16:20:14.999660  | value_loss/Min                     4.54022\n",
      "2024-01-07 16:20:15.000342  | value_loss/Max                    24.4472\n",
      "2024-01-07 16:20:15.001289  | prior_entropy/Average             10.5276\n",
      "2024-01-07 16:20:15.001924  | prior_entropy/Std                  2.08368\n",
      "2024-01-07 16:20:15.002685  | prior_entropy/Median              10.476\n",
      "2024-01-07 16:20:15.003409  | prior_entropy/Min                  6.95101\n",
      "2024-01-07 16:20:15.004325  | prior_entropy/Max                 14.2731\n",
      "2024-01-07 16:20:15.004894  | post_entropy/Average               5.96599\n",
      "2024-01-07 16:20:15.005778  | post_entropy/Std                   1.44525\n",
      "2024-01-07 16:20:15.006542  | post_entropy/Median                6.14578\n",
      "2024-01-07 16:20:15.007787  | post_entropy/Min                   3.38262\n",
      "2024-01-07 16:20:15.008592  | post_entropy/Max                   9.27349\n",
      "2024-01-07 16:20:15.009405  | divergence/Average                 3.6616\n",
      "2024-01-07 16:20:15.010024  | divergence/Std                     0.866976\n",
      "2024-01-07 16:20:15.010741  | divergence/Median                  3.34641\n",
      "2024-01-07 16:20:15.011310  | divergence/Min                     3\n",
      "2024-01-07 16:20:15.011838  | divergence/Max                     6.87138\n",
      "2024-01-07 16:20:15.013024  | reward_loss/Average                3.54187\n",
      "2024-01-07 16:20:15.013693  | reward_loss/Std                    0.405914\n",
      "2024-01-07 16:20:15.014482  | reward_loss/Median                 3.53207\n",
      "2024-01-07 16:20:15.015332  | reward_loss/Min                    2.6747\n",
      "2024-01-07 16:20:15.016083  | reward_loss/Max                    4.73364\n",
      "2024-01-07 16:20:15.016823  | image_loss/Average             11320.5\n",
      "2024-01-07 16:20:15.017561  | image_loss/Std                     5.21386\n",
      "2024-01-07 16:20:15.018098  | image_loss/Median              11319.9\n",
      "2024-01-07 16:20:15.019604  | image_loss/Min                 11310.4\n",
      "2024-01-07 16:20:15.020283  | image_loss/Max                 11341.3\n",
      "2024-01-07 16:20:15.021097  | pcont_loss/Average                 0.0251397\n",
      "2024-01-07 16:20:15.022046  | pcont_loss/Std                     0.00580923\n",
      "2024-01-07 16:20:15.023033  | pcont_loss/Median                  0.0256254\n",
      "2024-01-07 16:20:15.024017  | pcont_loss/Min                     0.0111812\n",
      "2024-01-07 16:20:15.024896  | pcont_loss/Max                     0.0364804\n",
      "2024-01-07 16:20:15.025737  | -----------------------------  --------------\n",
      "2024-01-07 16:20:15.026687  | dreamer_assault_0 itr #8999 Optimizing over 1000 iterations.\n",
      "Warning: No valid output stream.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Imagination:  23%|██▎       | 23/100 [00:29<01:39,  1.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m log_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/eddy/Projects/RL_project/logs_atari\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mbuild_and_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massault\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_ID\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcuda_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43meval\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlast\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 95\u001b[0m, in \u001b[0;36mbuild_and_train\u001b[0;34m(log_dir, game, run_ID, cuda_idx, eval, save_model, load_model_path)\u001b[0m\n\u001b[1;32m     85\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdreamer_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m game\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m logger_context(\n\u001b[1;32m     87\u001b[0m     log_dir,\n\u001b[1;32m     88\u001b[0m     run_ID,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m     use_summary_writer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     94\u001b[0m ):\n\u001b[0;32m---> 95\u001b[0m     \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/RL_project/rlpyt/rlpyt/runners/minibatch_rl.py:261\u001b[0m, in \u001b[0;36mMinibatchRl.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m samples, traj_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampler\u001b[38;5;241m.\u001b[39mobtain_samples(itr)\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mtrain_mode(itr)\n\u001b[0;32m--> 261\u001b[0m opt_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore_diagnostics(itr, traj_infos, opt_info)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (itr \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_interval_itrs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Projects/RL_project/algorithm.py:220\u001b[0m, in \u001b[0;36mDreamer.optimize_agent\u001b[0;34m(self, itr, samples, sampler_itr)\u001b[0m\n\u001b[1;32m    216\u001b[0m samples_from_replay \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_buffer\u001b[38;5;241m.\u001b[39msample_batch(\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_length\n\u001b[1;32m    218\u001b[0m )\n\u001b[1;32m    219\u001b[0m buffed_samples \u001b[38;5;241m=\u001b[39m buffer_to(samples_from_replay, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 220\u001b[0m model_loss, actor_loss, value_loss, loss_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuffed_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/Projects/RL_project/algorithm.py:312\u001b[0m, in \u001b[0;36mDreamer.loss\u001b[0;34m(self, samples, sample_itr, opt_itr)\u001b[0m\n\u001b[1;32m    310\u001b[0m feat \u001b[38;5;241m=\u001b[39m get_feat(post)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m#print('BELLA FRATÈ, QUESTA È LA DIMENSIONE  DI feat:', feat.size())\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m image_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m reward_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mreward_model(feat)\n\u001b[1;32m    314\u001b[0m reward_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmean(reward_pred\u001b[38;5;241m.\u001b[39mlog_prob(reward))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/RL_project/models/My_Observation.py:121\u001b[0m, in \u001b[0;36mObservationDec.forward\u001b[0;34m(self, encoding)\u001b[0m\n\u001b[1;32m    119\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x)\n\u001b[1;32m    120\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(x, (\u001b[38;5;241m*\u001b[39mbatch_shape, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize))\n\u001b[0;32m--> 121\u001b[0m obs_dist \u001b[38;5;241m=\u001b[39m td\u001b[38;5;241m.\u001b[39mIndependent(\u001b[43mtd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs_dist\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/distributions/normal.py:51\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, loc, scale, validate_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale \u001b[38;5;241m=\u001b[39m \u001b[43mbroadcast_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, Number) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scale, Number):\n\u001b[1;32m     53\u001b[0m         batch_shape \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mSize()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/distributions/utils.py:39\u001b[0m, in \u001b[0;36mbroadcast_all\u001b[0;34m(*values)\u001b[0m\n\u001b[1;32m     37\u001b[0m             options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mif\u001b[39;00m is_tensor_like(v) \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     40\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values]\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mnew_values)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mvalues)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/distributions/utils.py:39\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m             options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mif\u001b[39;00m is_tensor_like(v) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m                   \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values]\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mnew_values)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;241m*\u001b[39mvalues)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log_dir = os.path.abspath('/home/eddy/Projects/RL_project/logs_atari')\n",
    "\n",
    "build_and_train(\n",
    "    log_dir ,\n",
    "    game=\"assault\",\n",
    "    run_ID=0,\n",
    "    cuda_idx=0,\n",
    "    eval=False,\n",
    "    save_model=\"last\",\n",
    "    load_model_path=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
